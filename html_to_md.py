
# å¯¼å…¥æˆ‘ä»¬éœ€è¦çš„åº“
import asyncio  # å¯¼å…¥ asyncio åº“ï¼Œå› ä¸º Playwright æ˜¯åŸºäºå¼‚æ­¥ I/O çš„ï¼Œéœ€è¦å®ƒæ¥è¿è¡Œ
import argparse # å¯¼å…¥ argparse åº“ä»¥å¤„ç†å‘½ä»¤è¡Œå‚æ•°
from playwright.async_api import async_playwright # ä» playwright åº“ä¸­å¯¼å…¥å¼‚æ­¥ API
from bs4 import BeautifulSoup # å¯¼å…¥ BeautifulSoup ç”¨äºè§£æ HTML
from markdownify import markdownify # å¯¼å…¥ markdownify ç”¨äºå°† HTML è½¬ä¸º Markdown
import os # å¯¼å…¥ os åº“ï¼Œç”¨äºå¤„ç†æ–‡ä»¶è·¯å¾„
import re # å¯¼å…¥ re åº“ï¼Œç”¨äºæ­£åˆ™è¡¨è¾¾å¼æ“ä½œï¼Œä»¥å‡€åŒ–æ–‡ä»¶å

# --- 2. æŠ“å–HTMLå†…å®¹ ---

async def fetch_html_from_url(url: str) -> str | None:
    """
    ä½¿ç”¨ Playwright å¼‚æ­¥æŠ“å–æŒ‡å®š URL çš„ HTML å†…å®¹ã€‚
    :param url: ç›®æ ‡ç½‘é¡µçš„ URLã€‚
    :return: æˆåŠŸæ—¶è¿”å› HTML å­—ç¬¦ä¸²ï¼Œå¤±è´¥æ—¶è¿”å› Noneã€‚
    """
    print("ğŸš€ è„šæœ¬å¯åŠ¨ï¼Œå‡†å¤‡è¿æ¥ Playwright...")
    
    # é€šè¿‡async with è¯­å¥æ¥ç®¡ç† Playwright çš„ç”Ÿå‘½å‘¨æœŸï¼Œç¡®ä¿æµè§ˆå™¨è¢«æ­£ç¡®å…³é—­
    # asyncè¡¨ç¤ºä»£ç å¯ä»¥å¼‚æ­¥å¤„ç†ï¼Œæ‰€è°“å¼‚æ­¥ï¼Œæ˜¯æŒ‡å¯åœ¨æ‰§è¡Œä¸­æš‚åœï¼Œç­‰å¾…èµ„æºåˆ°ä½å†é‡å¯
    # withè¡¨ç¤ºä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œæ‰€è°“ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œæ˜¯æŒ‡è‡ªåŠ¨å¤„ç†ç›¸å…³åå°èµ„æºçš„å¼€å¯å’Œé‡Šæ”¾ï¼Œå¦‚æ–‡ä»¶ã€ç½‘ç»œè¿æ¥ç­‰
    # async_playwright()æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå¯åŠ¨ç›¸å…³èµ„æºï¼Œè¿”å›ä¸€ä¸ªPlaywright ä¸»æ§åˆ¶å¯¹è±¡ç»™p
    async with async_playwright() as p:
        try:
            # å¼‚æ­¥ï¼ˆå¯awaitï¼‰å¯åŠ¨ä¸€ä¸ª Chromium æµè§ˆå™¨å®ä¾‹ï¼ˆBrowserTypeå¯¹è±¡ï¼‰ã€‚headless=True è¡¨ç¤ºåœ¨åå°è¿è¡Œï¼Œä¸æ˜¾ç¤ºæµè§ˆå™¨çª—å£ã€‚
            # ä½ ä¹Ÿå¯ä»¥æ¢æˆ p.firefox.launch() æˆ– p.webkit.launch()
            # è¯¥æ–¹æ³•è¿”å›ä¸€ä¸ªBrowserå¯¹è±¡ï¼Œèµ‹å€¼ç»™browser
            browser = await p.chromium.launch(headless=True)
            print("âœ… æµè§ˆå™¨å·²å¯åŠ¨")

            # åœ¨æµè§ˆå™¨ä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„é¡µé¢ï¼ˆPageå¯¹è±¡ï¼‰ï¼Œå¹¶è®¾ç½®ä¸€ä¸ªçœŸå®çš„ User-Agent æ¥æ¨¡æ‹Ÿæ™®é€šç”¨æˆ·ï¼Œé˜²æ­¢åŸºç¡€çš„åçˆ¬è™«æ£€æµ‹ã€‚
            # user_agent æ˜¯ browser.new_page æ–¹æ³•çš„ä¸€ä¸ªå…³é”®å­—å‚æ•°ï¼ˆkeyword argumentï¼‰ã€‚
            page = await browser.new_page(
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"
            )
            print("âœ… é¡µé¢å·²åˆ›å»ºï¼Œå¹¶è®¾ç½®äº†è‡ªå®šä¹‰ User-Agent")
            print(f"ğŸŒ æ­£åœ¨å¯¼èˆªåˆ°: {url}")

            # è®¿é—®æˆ‘ä»¬æƒ³è¦æŠ“å–çš„ URLï¼Œå¹¶ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
            # await å…³é”®å­—è¡¨ç¤ºâ€œç­‰å¾…è¿™ä¸ªæ“ä½œå®Œæˆå†ç»§ç»­â€
            # å¢åŠ  timeout å‚æ•°ï¼Œå°†é»˜è®¤çš„30ç§’è¶…æ—¶å»¶é•¿åˆ°60ç§’ (60000æ¯«ç§’)
            await page.goto(url, wait_until="domcontentloaded", timeout=60000)
            print("âœ… é¡µé¢åŠ è½½å®Œæˆ")

            # è·å–å½“å‰é¡µé¢çš„å®Œæ•´ HTML å†…å®¹ï¼ˆä¹Ÿå°±æ˜¯html_contentï¼‰
            html_content = await page.content()
            print("ğŸ“„ å·²è·å–é¡µé¢ HTML å†…å®¹")

            # æ“ä½œå®Œæˆåï¼Œå…³é—­æµè§ˆå™¨
            await browser.close()
            print("âœ… æµè§ˆå™¨å·²å…³é—­")
            return html_content
        except Exception as e:
            print(f"âŒ åœ¨ä½¿ç”¨ Playwright æŠ“å–ç½‘é¡µæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None

# --- 2. è½¬åŒ–HTMLå†…å®¹ä¸ºMDæ–‡ä»¶ ---

def convert_html_to_markdown(html_content: str, selector: str | None, url: str) -> tuple[str, str] | None:
    """
    ä» HTML å­—ç¬¦ä¸²ä¸­æå–ç‰¹å®šå†…å®¹å¹¶è½¬æ¢ä¸º Markdownã€‚
    :param html_content: åŒ…å«å®Œæ•´ç½‘é¡µçš„ HTML å­—ç¬¦ä¸²ã€‚
    :param selector: ç”¨äºå®šä½å†…å®¹çš„ CSS é€‰æ‹©å™¨ã€‚å¦‚æœä¸º Noneï¼Œåˆ™è§¦å‘è‡ªåŠ¨æ£€æµ‹ã€‚
    :param url: åŸå§‹ç½‘é¡µçš„ URLï¼Œç”¨äºå¹³å°ç‰¹å®šè§„åˆ™çš„åˆ¤æ–­ã€‚
    :return: æˆåŠŸæ—¶è¿”å›ä¸€ä¸ªåŒ…å« (Markdownå­—ç¬¦ä¸², é¡µé¢æ ‡é¢˜) çš„å…ƒç»„ï¼Œå¤±è´¥æ—¶è¿”å› Noneã€‚
    """
    
    print("\nğŸ” å¼€å§‹è§£æå†…å®¹...")
    # BeautifulSoup æ¥æ”¶å‰é¢ç”Ÿæˆçš„ç½‘é¡µå­—ç¬¦ä¸²ï¼Œè§£æç”Ÿæˆå†…éƒ¨çš„æ ‘çŠ¶æ•°æ®ç»“æ„
    # â€œhtml.parserâ€æ˜¯è§£æå™¨ï¼Œè¿˜æœ‰lxmlã€html5lib
    # è¿™ä¸ª soup å¯¹è±¡ç°åœ¨æ˜¯æ•´ä¸ª HTML æ–‡æ¡£çš„ Pythonic è¡¨ç¤º,ã€‚
    # ä½ å¯ä»¥æŠŠå®ƒçœ‹ä½œä¸€ä¸ªå¤æ‚çš„ã€åµŒå¥—çš„ Python å¯¹è±¡ï¼Œå®ƒå®Œæ•´åœ°æ˜ å°„äº†åŸå§‹ HTML çš„æ ‡ç­¾ã€å±æ€§å’Œæ–‡æœ¬å†…å®¹ã€‚
    soup = BeautifulSoup(html_content, "html5lib")

    # æå–ç½‘é¡µæ ‡é¢˜ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™ä½¿ç”¨é»˜è®¤å€¼
    page_title = "Untitled"
    if soup.title and soup.title.string:
        page_title = soup.title.string.strip()
    # åˆå§‹åŒ–å†…å®¹å…ƒç´ å˜é‡
    content_element = None

    # æ­¥éª¤ 1: å¦‚æœç”¨æˆ·æä¾›äº†é€‰æ‹©å™¨ï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨
    if selector:
        print(f"ğŸ” ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„é€‰æ‹©å™¨: '{selector}'")
        # åœ¨å·²ç»è§£æçš„ HTML æ–‡æ¡£ä¸­ï¼Œæ ¹æ®ä¸€ä¸ª CSS é€‰æ‹©å™¨æ¥æŸ¥æ‰¾å¹¶è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„ HTML å…ƒç´ ã€‚
        # bs4.element.Tag å¯¹è±¡ï¼šcontent_element å°†æ˜¯ä¸€ä¸ªä»£è¡¨è¯¥ HTML æ ‡ç­¾åŠå…¶æ‰€æœ‰å­å†…å®¹çš„ Tag å¯¹è±¡ã€‚
        content_element = soup.select_one(selector)
        if not content_element:
            print(f"âŒ æœªèƒ½æ‰¾åˆ°åŒ¹é…é€‰æ‹©å™¨ '{selector}' çš„å†…å®¹ã€‚è¯·æ£€æŸ¥é€‰æ‹©å™¨æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ç½‘é¡µç»“æ„æ˜¯å¦å·²æ”¹å˜ã€‚")
            # å³ä½¿æŒ‡å®šäº†é€‰æ‹©å™¨ä½†å¤±è´¥äº†ï¼Œä¹Ÿç›´æ¥è¿”å›ï¼Œä¸å†è¿›è¡Œåç»­å°è¯•
            return None

    # æ­¥éª¤ 2: å¦‚æœæ²¡æœ‰ç”¨æˆ·é€‰æ‹©å™¨ï¼Œåˆ™æ£€æŸ¥æ˜¯å¦æœ‰å¹³å°ç‰¹å®šè§„åˆ™ï¼ˆä¾‹å¦‚å¾®ä¿¡å…¬ä¼—å·ï¼‰
    if not content_element and "mp.weixin.qq.com" in url:
        print("ğŸ’¡ æ£€æµ‹åˆ°å¾®ä¿¡å…¬ä¼—å·æ–‡ç« ï¼Œå°è¯•ä½¿ç”¨ä¸“ç”¨é€‰æ‹©å™¨ '#js_content'...")
        wechat_selector = "#js_content"
        content_element = soup.select_one(wechat_selector)
        if content_element:
            print(f"   âœ… æˆåŠŸåŒ¹é…åˆ°å†…å®¹: '{wechat_selector}'")
            selector = wechat_selector # è®°å½•ä¸‹æˆåŠŸçš„é€‰æ‹©å™¨ï¼Œç”¨äºåç»­æ‰“å°ä¿¡æ¯
        else:
            # å¦‚æœå¾®ä¿¡ä¸“ç”¨é€‰æ‹©å™¨ä¹Ÿå¤±è´¥äº†ï¼ˆè™½ç„¶ä¸å¤ªå¯èƒ½ï¼‰ï¼Œåˆ™æ‰“å°æç¤ºå¹¶ç»§ç»­è¿›è¡Œé€šç”¨æ£€æµ‹
            print(f"   âŒ æœªèƒ½é€šè¿‡ '{wechat_selector}' æ‰¾åˆ°å†…å®¹ï¼Œå°†ç»§ç»­é€šç”¨æ£€æµ‹...")

    # æ­¥éª¤ 3: å¦‚æœä»¥ä¸Šæ–¹æ³•éƒ½æœªæˆåŠŸï¼Œåˆ™å¯åŠ¨é€šç”¨çš„é¢„è®¾åˆ—è¡¨è¿›è¡Œè‡ªåŠ¨æ£€æµ‹
    if not content_element:
        print("ğŸ¤– å¯åŠ¨é€šç”¨é¢„è®¾è§„åˆ™è¿›è¡Œæ£€æµ‹...")
        # å®šä¹‰ä¸€ä¸ªé«˜è´¨é‡çš„å€™é€‰é€‰æ‹©å™¨åˆ—è¡¨ï¼ŒæŒ‰å¯èƒ½æ€§ä»é«˜åˆ°ä½æ’åº
        candidate_selectors = [
            'article', 'main', '#content', '#main-content', '#main',
            '.post-body', '.entry-content', '.article-body',
        ]
        for candidate in candidate_selectors:
            print(f"   å°è¯•å€™é€‰é€‰æ‹©å™¨: '{candidate}'...")
            content_element = soup.select_one(candidate)
            if content_element:
                print(f"   âœ… æˆåŠŸåŒ¹é…åˆ°å†…å®¹: '{candidate}'")
                selector = candidate # è®°å½•ä¸‹æˆåŠŸçš„é€‰æ‹©å™¨ï¼Œç”¨äºåç»­æ‰“å°ä¿¡æ¯
                break # æ‰¾åˆ°åç«‹å³è·³å‡ºå¾ªç¯
    
    # æ­¥éª¤ 4: å¦‚æœä»¥ä¸Šæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œåˆ™å¯åŠ¨æœ€ç»ˆçš„æ™ºèƒ½åˆ†æ
    if not content_element:
        print("âŒ é¢„è®¾è§„åˆ™æ£€æµ‹å¤±è´¥ï¼Œå¯åŠ¨æœ€ç»ˆæ™ºèƒ½åˆ†ææ¨¡å¼...")
        print("   ğŸ¤– æ­£åœ¨åˆ†æé¡µé¢ç»“æ„ï¼Œä¸ºæ‚¨å¯»æ‰¾å¯èƒ½çš„é€‰æ‹©å™¨...")
        potential_selectors = set() # ä½¿ç”¨é›†åˆæ¥é¿å…é‡å¤
        # éå†é¡µé¢ä¸Šæ‰€æœ‰çš„æ ‡ç­¾
        for element in soup.find_all(True):
            # è®¡ç®—æ ‡ç­¾å†…çº¯æ–‡æœ¬çš„é•¿åº¦ï¼Œå¿½ç•¥ç©ºç™½
            text_length = len(element.get_text(strip=True))
            # æˆ‘ä»¬åªå…³å¿ƒé‚£äº›åŒ…å«å¤§é‡æ–‡æœ¬çš„å®¹å™¨
            if text_length > 200: # æ–‡æœ¬é•¿åº¦é˜ˆå€¼å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
                if element.get('id'):
                    potential_selectors.add(f"#{element.get('id')}")
                if element.get('class'):
                    # åªé€‰æ‹©çœ‹èµ·æ¥ä¸åƒçº¯æ ·å¼ã€æ›´æœ‰æ„ä¹‰çš„ç±»å
                    meaningful_classes = [cls for cls in element.get('class') if len(cls) > 4 and not cls.isdigit()]
                    for cls in meaningful_classes:
                        potential_selectors.add(f".{cls}")
        
        if potential_selectors:
            print("\n   ğŸ’¡ å»ºè®®ï¼šæ‚¨å¯ä»¥å°è¯•ä½¿ç”¨ `-s` å‚æ•°å¹¶é…åˆä»¥ä¸‹å¯èƒ½æœ‰æ•ˆçš„é€‰æ‹©å™¨ä¹‹ä¸€å†æ¬¡è¿è¡Œï¼š")
            # æŒ‰é•¿åº¦å¯¹å»ºè®®çš„é€‰æ‹©å™¨è¿›è¡Œæ’åºï¼Œé€šå¸¸æ›´çŸ­çš„æ›´å…·ä»£è¡¨æ€§
            for ps in sorted(list(potential_selectors), key=len):
                print(f"      -s \"{ps}\"")
        else:
            print("   ğŸ˜” æœªèƒ½åœ¨é¡µé¢ä¸Šæ‰¾åˆ°åŒ…å«å¤§é‡æ–‡æœ¬çš„åŒºåŸŸã€‚")
        
        return None

    print(f"âœ… æˆåŠŸæ‰¾åˆ°å†…å®¹å…ƒç´  (åŒ¹é…é€‰æ‹©å™¨: '{selector}')")


    # å°† HTML å…ƒç´ è½¬æ¢ä¸º Markdownæ–‡æ¡£å­—ç¬¦ä¸²ï¼Œmarkdownify()å‡½æ•°
    # heading_styleæ§åˆ¶ markdownify åœ¨å°† HTML æ ‡é¢˜æ ‡ç­¾ï¼ˆå¦‚ <h1>, <h2>, <h3> ç­‰ï¼‰è½¬æ¢ä¸º Markdown æ ‡é¢˜æ—¶æ‰€ä½¿ç”¨çš„æ ·å¼ã€‚
    # strip=['a'] å‚æ•°å¯ä»¥åœ¨è½¬æ¢å‰ç§»é™¤æ‰€æœ‰<a>æ ‡ç­¾ï¼Œä»¥è·å¾—æ›´å¹²å‡€çš„æ–‡æœ¬ã€‚
    markdown_text = markdownify(str(content_element), heading_style="ATX", strip=['a'])
    print(f"ğŸ”„ å·²å°† HTML (æ ‡é¢˜: {page_title}) è½¬æ¢ä¸º Markdown")
    return markdown_text, page_title

def save_to_file(content: str, output_path: str):
    """
    å°†å­—ç¬¦ä¸²å†…å®¹ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„çš„æ–‡ä»¶ä¸­ã€‚
    :param content: è¦ä¿å­˜çš„å­—ç¬¦ä¸²å†…å®¹ã€‚
    :param output_path: ç›®æ ‡æ–‡ä»¶è·¯å¾„ã€‚
    """
    try:

        with open(output_path, "w", encoding="utf-8") as f: 
            f.write(content)
        print(f"ğŸ’¾ æ–‡ä»¶å·²æˆåŠŸä¿å­˜åˆ°: {os.path.abspath(output_path)}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")

def sanitize_filename(filename: str) -> str:
    """
    ç§»é™¤æˆ–æ›¿æ¢æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦ã€‚
    :param filename: åŸå§‹æ–‡ä»¶åï¼ˆé€šå¸¸æ˜¯ç½‘é¡µæ ‡é¢˜ï¼‰ã€‚
    :return: æ¸…ç†åå¯ä»¥å®‰å…¨ç”¨ä½œæ–‡ä»¶åçš„å­—ç¬¦ä¸²ã€‚
    """
    # ç§»é™¤éæ³•å­—ç¬¦ï¼š \ / : * ? " < > |
    return re.sub(r'[\\/*?:"<>|]', "", filename).strip()

# --- 3. ä¸»æµç¨‹ç¼–æ’å‡½æ•° ---

async def main():
    """
    ç¨‹åºçš„ä¸»å¼‚æ­¥å…¥å£ï¼Œè´Ÿè´£ç¼–æ’æ•´ä¸ªæŠ“å–ã€è½¬æ¢å’Œä¿å­˜çš„å·¥ä½œæµã€‚
    """
    # ä½¿ç”¨ argparse è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="ä¸€ä¸ªé€šç”¨çš„ç½‘é¡µå†…å®¹æŠ“å–å¹¶è½¬æ¢ä¸º Markdown çš„å·¥å…·ã€‚")
    parser.add_argument("url", help="è¦æŠ“å–çš„ç›®æ ‡ç½‘é¡µ URLã€‚") # ä½ç½®å‚æ•°ï¼Œå¿…éœ€
    parser.add_argument("-s", "--selector", help="æ‰‹åŠ¨æŒ‡å®šCSSé€‰æ‹©å™¨ã€‚è‹¥ä¸æä¾›ï¼Œåˆ™è‡ªåŠ¨æ£€æµ‹ã€‚") # å¯é€‰å‚æ•°
    # ä¿®æ”¹-oå‚æ•°ï¼Œä½¿å…¶é»˜è®¤å€¼ä¸ºNoneï¼Œä»¥ä¾¿æˆ‘ä»¬åˆ¤æ–­ç”¨æˆ·æ˜¯å¦çœŸçš„è¾“å…¥äº†å®ƒ
    parser.add_argument("-o", "--output", help="è¾“å‡ºçš„ Markdown æ–‡ä»¶è·¯å¾„ã€‚å¦‚æœæœªæä¾›ï¼Œå°†æ ¹æ®ç½‘é¡µæ ‡é¢˜è‡ªåŠ¨ç”Ÿæˆã€‚")
    args = parser.parse_args()

    # 1. æå–
    html_content = await fetch_html_from_url(args.url)
    if not html_content:
        return

    # 2. è½¬æ¢
    conversion_result = convert_html_to_markdown(html_content, args.selector, args.url) # å°† URL ä¹Ÿä¼ é€’è¿›å»
    if not conversion_result:
        return
    
    markdown_text, page_title = conversion_result

    # å†³å®šæœ€ç»ˆçš„è¾“å‡ºæ–‡ä»¶å
    if args.output:
        # å¦‚æœç”¨æˆ·é€šè¿‡ -o æŒ‡å®šäº†æ–‡ä»¶åï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„
        output_filename = args.output
    else:
        # å¦åˆ™ï¼Œä½¿ç”¨ä»ç½‘é¡µæå–çš„æ ‡é¢˜æ¥ç”Ÿæˆæ–‡ä»¶å
        output_filename = sanitize_filename(page_title) + ".md"

    # 3. ä¿å­˜
    save_to_file(markdown_text, output_filename)

# --- 4. ç¨‹åºä¸»å…¥å£ ---

if __name__ == "__main__":
    # å› ä¸ºæˆ‘ä»¬çš„æ ¸å¿ƒå‡½æ•°æ˜¯å¼‚æ­¥çš„ï¼Œæ‰€ä»¥éœ€è¦ä½¿ç”¨ asyncio.run() æ¥å¯åŠ¨å®ƒ
    asyncio.run(main())
