"""
è„šæœ¬åç§°: æ‰¹é‡æ€»ç»“å·¥å…· (note_summarize.py)

åŠŸèƒ½æè¿°:
    æœ¬è„šæœ¬ä¸“é—¨ç”¨äºæ‰¹é‡å¤„ç†æŒ‡å®šæ–‡ä»¶å¤¹å†…çš„ Markdown æ–‡ä»¶ã€‚
    å®ƒä¼šè‡ªåŠ¨éå†æ–‡ä»¶å¤¹ï¼ŒæŸ¥æ‰¾æ–‡ä»¶ä¸­é¢„è®¾çš„â€œ# æ€»ç»“æç‚¼â€åŒºåŸŸï¼Œ
    å¦‚æœè¯¥åŒºåŸŸä¸ºç©ºï¼Œåˆ™è°ƒç”¨ AI æ¨¡å‹å¯¹æ–‡ä»¶å†…å®¹è¿›è¡Œæ€»ç»“ï¼Œå¹¶å°†ç»“æœå†™å›åŸæ–‡ä»¶ã€‚

ä½¿ç”¨æ–¹æ³•:
    åœ¨ç»ˆç«¯ä¸­è¿è¡Œ: `python note_process/note_summarize.py <æ–‡ä»¶å¤¹è·¯å¾„> [é€‰é¡¹]`

    1.  **åŸºæœ¬ç”¨æ³•**:
        `python note_process/note_summarize.py "D:\\MyNotes"`
        -   ç¨‹åºä¼šæç¤ºæ‚¨è¾“å…¥ç”¨äº AI æ€»ç»“çš„æç¤ºè¯æ¨¡æ¿ã€‚

    2.  **ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šæç¤ºè¯**:
        `python note_process/note_summarize.py "D:\\MyNotes" --prompt "è¯·æ€»ç»“ä»¥ä¸‹å†…å®¹ï¼š{activeNote}"`

    3.  **ä»æ–‡ä»¶åŠ è½½æç¤ºè¯**:
        `python note_process/note_summarize.py "D:\\MyNotes" --prompt-file "my_prompt_template.txt"`

    **é‡è¦**: æç¤ºè¯æ¨¡æ¿ä¸­å¿…é¡»åŒ…å« `{activeNote}` å ä½ç¬¦ï¼Œå®ƒå°†è¢«æ›¿æ¢ä¸ºæ¯ä¸ªæ–‡ä»¶çš„å®é™…å†…å®¹ã€‚

é…ç½®:
    - ä¾èµ–äºé¡¹ç›®æ ¹ç›®å½•çš„ `.env` æ–‡ä»¶æ¥è·å– AI æœåŠ¡çš„ç›¸å…³é…ç½®ï¼ˆAPI Key, URL, Model Nameç­‰ï¼‰ã€‚

ä¾èµ–:
    - `python-dotenv`
    - `requests` (é€šè¿‡ ai_service é—´æ¥ä½¿ç”¨)
"""
import os
import sys
import re
import argparse
from dotenv import load_dotenv

# --- åŠ¨æ€æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path ---
# è¿™æ®µä»£ç æ˜¯ä¸ºäº†è§£å†³è„šæœ¬åœ¨å­ç›®å½•ä¸­è¿è¡Œæ—¶ï¼Œæ— æ³•æ‰¾åˆ°ä½äºæ ¹ç›®å½•çš„æ¨¡å—ï¼ˆå¦‚ ai_serviceï¼‰çš„é—®é¢˜ã€‚
# 1. è·å–å½“å‰è„šæœ¬æ–‡ä»¶ï¼ˆnote_summarize.pyï¼‰çš„ç»å¯¹è·¯å¾„ã€‚
#    __file__ æ˜¯ä¸€ä¸ª Python å†…ç½®å˜é‡ï¼Œä»£è¡¨å½“å‰è„šæœ¬çš„æ–‡ä»¶åã€‚
current_file_path = os.path.abspath(__file__)
# 2. è·å– note_summarize.py æ‰€åœ¨çš„ç›®å½•ï¼Œå³ 'd:\Documents\Assistant\note_process'ã€‚
current_dir = os.path.dirname(current_file_path)
# 3. è·å– 'note_process' ç›®å½•çš„ä¸Šçº§ç›®å½•ï¼Œå³é¡¹ç›®çš„æ ¹ç›®å½• 'd:\Documents\Assistant'ã€‚
project_root = os.path.dirname(current_dir)
# 4. å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° Python è§£é‡Šå™¨çš„æ¨¡å—æœç´¢è·¯å¾„åˆ—è¡¨ (sys.path) çš„æœ€å‰é¢ã€‚
#    è¿™æ ·ï¼Œå½“æ‰§è¡Œ import ai_service æ—¶ï¼ŒPython å°±èƒ½åœ¨æ ¹ç›®å½•ä¸­æ‰¾åˆ° ai_service.py æ–‡ä»¶ã€‚
sys.path.insert(0, project_root)

from ai_service import AIAssistantService # ä»æˆ‘ä»¬åˆ›å»ºçš„å…±äº«æ¨¡å—ä¸­å¯¼å…¥æœåŠ¡ç±»

load_dotenv()

# --- 1. é…ç½®ç¨‹åºæ‰€éœ€çš„å˜é‡ ---
API_KEY = os.getenv("ALIYUN_API_KEY")
if not API_KEY:
    print("é”™è¯¯ï¼šæœªæ‰¾åˆ°ALIYUN_API_KEYç¯å¢ƒå˜é‡ï¼è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®ã€‚")
    sys.exit(1)

API_URL = os.getenv("ALIYUN_API_URL")
if not API_URL:
    print("é”™è¯¯ï¼šæœªæ‰¾åˆ°ALIYUN_API_URLç¯å¢ƒå˜é‡ï¼è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®ã€‚")
    sys.exit(1)

MODEL_NAME = os.getenv("ALIYUN_MODEL_NAME")
if not MODEL_NAME:
    print("è­¦å‘Šï¼šæœªæ‰¾åˆ°ALIYUN_MODEL_NAMEç¯å¢ƒå˜é‡ï¼è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®ã€‚")
    sys.exit(1)

TEMPERATURE = float(os.getenv("TEMPERATURE", 0.5))

SUMMARY_HEADING_MARKER = "# æ€»ç»“æç‚¼\n"
SUMMARY_PATTERN = re.compile(rf"({re.escape(SUMMARY_HEADING_MARKER)})", re.DOTALL)

# --- 2. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---
def process_folder_for_summaries(folder_path, ai_service, prompt_template):
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰Markdownæ–‡ä»¶ï¼ŒæŸ¥æ‰¾æ€»ç»“æç‚¼åŒºåŸŸï¼Œ
    å¦‚æœè¯¥åŒºåŸŸä¸ºç©ºï¼Œåˆ™è°ƒç”¨AIè¿›è¡Œæ€»ç»“å¹¶å†™å…¥æ–‡ä»¶ã€‚
    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    :param ai_service: AI æœåŠ¡å®ä¾‹ã€‚
    :param prompt_template: ç”¨äºç”ŸæˆAIè¯·æ±‚çš„æç¤ºè¯æ¨¡æ¿ã€‚
    """
    print(f"ğŸ“ å¼€å§‹æ‰«ææ–‡ä»¶å¤¹ï¼š'{folder_path}'")
    processed_count = 0
    skipped_count = 0
    error_count = 0

    if "{activeNote}" not in prompt_template:
        print("âš ï¸ è­¦å‘Šï¼šæä¾›çš„æç¤ºè¯æ¨¡æ¿ä¸­æœªæ‰¾åˆ° '{activeNote}' å ä½ç¬¦ã€‚AIå¯èƒ½æ— æ³•è·å–æ–‡ä»¶å†…å®¹ã€‚")

    for root, _, files in os.walk(folder_path):
        for file_name in files:
            if not file_name.lower().endswith('.md'):
                continue

            file_path = os.path.join(root, file_name)
            print(f"\n--- æ­£åœ¨å¤„ç†æ–‡ä»¶: {file_name} ---")

            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                match = SUMMARY_PATTERN.search(content)
                if not match:
                    print(f"   â­ï¸ è·³è¿‡ï¼šæœªæ‰¾åˆ°æ€»ç»“æç‚¼çš„æ ‡é¢˜æ ‡è®° ('{SUMMARY_HEADING_MARKER.strip()}')ã€‚")
                    skipped_count += 1
                    continue

                summary_prompt = prompt_template.format(activeNote=content)
                temp_history = [{"role": "user", "content": summary_prompt}]
                
                print("   ğŸ¤– æ­£åœ¨è¯·æ±‚ AI ç”Ÿæˆå†…å®¹...")
                ai_summary = "".join(ai_service.stream_chat_completion(temp_history))

                if not ai_summary.strip():
                    print(f"   â­ï¸ è·³è¿‡ï¼šAI æœªè¿”å›æœ‰æ•ˆå†…å®¹ã€‚")
                    skipped_count += 1
                    continue

                # --- æ–°å¢ï¼šå°†æ¨¡å‹åç§°é™„åŠ åˆ°æ€»ç»“æœ«å°¾ ---
                # 1. ä» AI æœåŠ¡å®ä¾‹ä¸­è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°
                model_name = ai_service.model_name
                # 2. åˆ›å»ºä¸€ä¸ªæ ¼å¼åŒ–çš„ã€åŒ…å«æ¨¡å‹ä¿¡æ¯çš„ Markdown å­—ç¬¦ä¸²
                model_info_str = f"\n\n> æ€»ç»“ç”± *{model_name}* ç”Ÿæˆ"
                # 3. å°† AI æ€»ç»“ã€æ¨¡å‹ä¿¡æ¯å’Œå¿…è¦çš„æ¢è¡Œç¬¦æ‹¼æ¥æˆæœ€ç»ˆè¦æ’å…¥çš„å†…å®¹
                content_to_insert = ai_summary.strip() + model_info_str + "\n"

                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢ï¼Œå°†æ‹¼æ¥å¥½çš„å®Œæ•´å†…å®¹æ’å…¥åˆ°â€œ# æ€»ç»“æç‚¼â€æ ‡é¢˜ä¸‹æ–¹
                new_content = SUMMARY_PATTERN.sub(r"\1" + content_to_insert, content, 1)
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                print(f"   âœ… æˆåŠŸæ’å…¥å†…å®¹å¹¶æ›´æ–°æ–‡ä»¶ã€‚")
                processed_count += 1
                    
            except Exception as e:
                print(f"   âŒ å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                error_count += 1
                continue
    
    print("\n--- æ‰¹å¤„ç†å®Œæˆ ---")
    print(f"æˆåŠŸæ›´æ–°: {processed_count} ä¸ªæ–‡ä»¶")
    print(f"è·³è¿‡: {skipped_count} ä¸ªæ–‡ä»¶")
    print(f"å¤±è´¥: {error_count} ä¸ªæ–‡ä»¶")
    print("------------------")

# --- 3. ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="æ‰¹é‡ä¸º Markdown æ–‡ä»¶ç”Ÿæˆ AI æ€»ç»“ã€‚")
    parser.add_argument("folder_path", help="åŒ…å« Markdown æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚")
    prompt_group = parser.add_mutually_exclusive_group()
    prompt_group.add_argument('--prompt', dest='prompt_string', help="ç›´æ¥åœ¨å‘½ä»¤è¡Œä¸­æä¾›æç¤ºè¯æ¨¡æ¿ã€‚")
    prompt_group.add_argument('--prompt-file', dest='prompt_file_path', help="ä»æŒ‡å®šæ–‡ä»¶ä¸­åŠ è½½æç¤ºè¯æ¨¡æ¿ã€‚")
    args = parser.parse_args()

    if not os.path.isdir(args.folder_path):
        print(f"âŒ é”™è¯¯ï¼šæä¾›çš„è·¯å¾„ '{args.folder_path}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ–‡ä»¶å¤¹ã€‚")
        sys.exit(1)

    prompt_template = ""
    if args.prompt_string:
        prompt_template = args.prompt_string
    elif args.prompt_file_path:
        try:
            with open(args.prompt_file_path, 'r', encoding='utf-8') as f:
                prompt_template = f.read()
        except Exception as e:
            print(f"âŒ è¯»å–æç¤ºè¯æ–‡ä»¶ '{args.prompt_file_path}' æ—¶å‡ºé”™: {e}")
            sys.exit(1)
    else:
        default_prompt = "è¯·ä½ ä»”ç»†é˜…è¯»ä»¥ä¸‹æ–‡æœ¬ï¼Œå¹¶æç‚¼å‡ºä¸»è¦å†…å®¹å’Œå…³é”®ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½ç®€æ´çš„æ€»ç»“ã€‚è¯·ç›´æ¥è¾“å‡ºæ€»ç»“å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•é¢å¤–çš„å‰ç¼€æˆ–åç¼€ã€‚\n\næ–‡æœ¬å†…å®¹:\n```\n{activeNote}\n```"
        print("\næ‰¹å¤„ç†æ¨¡å¼éœ€è¦ä¸€ä¸ªæç¤ºè¯æ¨¡æ¿ã€‚æ¨¡æ¿ä¸­å¿…é¡»åŒ…å« '{activeNote}' å ä½ç¬¦ã€‚")
        print(f"\nç¤ºä¾‹ (é»˜è®¤æ¨¡æ¿):\n---\n{default_prompt}\n---")
        user_prompt = input("\nè¯·è¾“å…¥ä½ çš„æç¤ºè¯æ¨¡æ¿ (ç›´æ¥æŒ‰ Enter ä½¿ç”¨é»˜è®¤æ¨¡æ¿): \n")
        prompt_template = user_prompt.strip() or default_prompt

    ai_service = AIAssistantService(API_KEY, MODEL_NAME, API_URL, TEMPERATURE)
    process_folder_for_summaries(args.folder_path, ai_service, prompt_template)
