"""
è„šæœ¬åç§°: AI åŠ©æ‰‹ (ai_assistant.py)

åŠŸèƒ½æè¿°:
    è¿™æ˜¯ä¸€ä¸ªå¤šåŠŸèƒ½çš„ AI èŠå¤©æœºå™¨äººï¼Œæ”¯æŒå‘½ä»¤è¡Œç•Œé¢ (CLI) å’Œå›¾å½¢ç”¨æˆ·ç•Œé¢ (Web UI)ã€‚
    å®ƒé€šè¿‡é˜¿é‡Œäº‘çš„é€šä¹‰åƒé—®æ¨¡å‹æä¾›æ™ºèƒ½å¯¹è¯æœåŠ¡ï¼Œå¹¶æ”¯æŒæµå¼å“åº”ä»¥å®ç°å®æ—¶äº¤äº’ã€‚
    CLI æ¨¡å¼ä¸‹å…·æœ‰å¯¹è¯å†å²æŒä¹…åŒ–åŠŸèƒ½ï¼ŒWeb UI æ¨¡å¼åˆ™æä¾›æ›´å‹å¥½çš„å¯è§†åŒ–äº¤äº’ã€‚
    æ­¤å¤–ï¼ŒCLI æ¨¡å¼è¿˜æ”¯æŒå°†å¤–éƒ¨æ–‡ä»¶å†…å®¹æ³¨å…¥åˆ°å¯¹è¯ä¸Šä¸‹æ–‡ä¸­ï¼Œä»¥ä¾¿ AI è¿›è¡Œæ›´æ·±å…¥çš„åˆ†æå’Œè®¨è®ºã€‚

    æ³¨æ„ï¼šåŸæœ‰çš„æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹åŠŸèƒ½å·²è¢«ç§»è‡³ `note_process/batch_summarize.py` è„šæœ¬ã€‚

ä½¿ç”¨æ–¹æ³•:
    1.  **CLI æ¨¡å¼ (é»˜è®¤çŸ­æœŸè®°å¿†)**:
        åœ¨ç»ˆç«¯ä¸­è¿è¡Œ: `python ai_assistant.py`
        -   ç›´æ¥è¾“å…¥é—®é¢˜ä¸ AI å¯¹è¯ã€‚
        -   è¾“å…¥ "quit", "exit", "bye", "goodbye" ä¹‹ä¸€å³å¯é€€å‡ºã€‚

    2.  **CLI æ¨¡å¼ (é€‰æ‹©è®°å¿†ç­–ç•¥ / ä¼šè¯)**:
        -   é•¿æœŸè®°å¿†: `python ai_assistant.py --mode long`
        -   ç¦ç”¨è®°å¿†: `python ai_assistant.py --mode no`
        -   æŒ‡å®šä¼šè¯: `python ai_assistant.py --mode long --session å·¥ä½œ`
            (ä¸åŒä¼šè¯çš„å†å²ä¼šåˆ†åˆ«ä¿å­˜åœ¨ç‹¬ç«‹æ–‡ä»¶ä¸­)

    3.  **CLI æ¨¡å¼ (å¸¦æ–‡ä»¶æ³¨å…¥)**:
        åœ¨ç»ˆç«¯ä¸­è¿è¡Œ: `python ai_assistant.py <æ–‡ä»¶è·¯å¾„> [å…¶å®ƒå‚æ•°]`
        -   ä¾‹å¦‚: `python ai_assistant.py notes/summary.md --mode long`
        -   AI ä¼šå…ˆé˜…è¯»æ–‡ä»¶å†…å®¹ï¼Œå†ç­‰å¾…ä½ çš„æé—®ã€‚

    4.  **Web UI æ¨¡å¼**:
        åœ¨ç»ˆç«¯ä¸­è¿è¡Œ: `python ai_assistant.py --gui`
        -   å¯åŠ¨åŸºäº Gradio çš„ Web ç•Œé¢ï¼Œå¯åœ¨æµè§ˆå™¨ä¸­ä¸ AI äº¤äº’ã€‚

é…ç½®:
    -   **API å¯†é’¥**: å¿…é¡»åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ `.env` æ–‡ä»¶ä¸­è®¾ç½® `ALIYUN_API_KEY` ç¯å¢ƒå˜é‡ã€‚
        ä¾‹å¦‚: `ALIYUN_API_KEY="your_api_key_here"`
    -   **ä»£ç†**: å¦‚æœéœ€è¦ï¼Œå¯ä»¥åœ¨ `PROXY_URL` å˜é‡ä¸­é…ç½®ä»£ç†æœåŠ¡å™¨åœ°å€ã€‚
    -   **å†å²è®°å½•**: é•¿æœŸè®°å¿†æ¨¡å¼ä¼šå°†å†å²ä¿å­˜åœ¨ `data/sessions/` ç›®å½•ä¸‹ï¼ˆå¯é€šè¿‡ `MEMORY_ROOT` è°ƒæ•´ï¼‰ã€‚

ä¾èµ–:
    -   `requests`
    -   `gradio`
    -   `python-dotenv`
    -   `json`
    -   `os`
    -   `sys`

æ³¨æ„äº‹é¡¹:
    -   Web UI æ¨¡å¼é»˜è®¤å¯ç”¨é•¿æœŸè®°å¿†ï¼Œå¯é€šè¿‡ç•Œé¢åˆ‡æ¢ä¸åŒä¼šè¯ã€‚
    -   ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–åº“ (`pip install -r requirements.txt`)ã€‚
"""
import os
import sys
import gradio as gr
import argparse
from dotenv import load_dotenv
# é¡¹ç›®è‡ªå¸¦çš„æœåŠ¡å¯¹è±¡ï¼Œè´Ÿè´£ä¸åç«¯å¤§æ¨¡å‹äº¤äº’
from ai_service import AIAssistantService
# ç»Ÿä¸€çš„ä¼šè¯è®°å¿†å­˜å‚¨å®ç°
from memory_store import MemoryStore

# è¯»å– .env æ–‡ä»¶åˆ°ç¯å¢ƒå˜é‡ä¸­ï¼Œè®©ä¸‹é¢çš„ os.getenv å¯ä»¥è·å–åˆ°é…ç½®
load_dotenv()

# --- 1. é…ç½®ç¨‹åºæ‰€éœ€çš„å˜é‡ ---

# ä»¥ä¸‹é…ç½®ç”¨äºé©±åŠ¨æ¨¡å‹è°ƒç”¨ï¼Œå…¨éƒ¨ä¾èµ–ç¯å¢ƒå˜é‡ã€‚
# è¿™æ ·åšçš„å¥½å¤„æ˜¯ä¸éœ€è¦æŠŠæ•æ„Ÿä¿¡æ¯å†™æ­»åœ¨ä»£ç é‡Œã€‚
API_KEY = os.getenv("ALIYUN_API_KEY") 
if not API_KEY: 
    print("é”™è¯¯ï¼šæœªæ‰¾åˆ°ALIYUN_API_KEYç¯å¢ƒå˜é‡ï¼") 
    print("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„APIå¯†é’¥") 
    exit(1) 

API_URL = os.getenv("ALIYUN_API_URL")
if not API_URL:
    print("é”™è¯¯ï¼šæœªæ‰¾åˆ°ALIYUN_API_URLç¯å¢ƒå˜é‡ï¼")
    print("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„APIåœ°å€")
    exit(1)

MODEL_NAME = os.getenv("ALIYUN_MODEL_NAME")
if not MODEL_NAME:
    print("è­¦å‘Šï¼šæœªæ‰¾åˆ°ALIYUN_MODEL_NAMEç¯å¢ƒå˜é‡ï¼")
    print("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„æ¨¡å‹åç§°")
    exit(1)

MEMORY_ROOT = os.getenv("MEMORY_ROOT", "data/sessions")
DEFAULT_SESSION_ID = "default"
TEMPERATURE = float(os.getenv("TEMPERATURE",0.5))

# å®ä¾‹åŒ–è®°å¿†å­˜å‚¨ï¼ŒCLI ä¸ GUI å…±ç”¨ï¼Œä¿è¯ä¼šè¯åˆ‡æ¢è¡Œä¸ºä¸€è‡´
memory_store = MemoryStore(root_dir=MEMORY_ROOT)

def history_to_chatbot_pairs(history):
    """
    å°†å®Œæ•´çš„æ¶ˆæ¯å†å²è½¬æ¢ä¸º Chatbot ç»„ä»¶éœ€è¦çš„ [user, assistant] åˆ—è¡¨ã€‚

    history å‚æ•°ä½¿ç”¨çš„æ˜¯ OpenAI å…¼å®¹æ ¼å¼ï¼š
    [
        {"role": "user", "content": "..."},
        {"role": "assistant", "content": "..."},
        ...
    ]
    è€Œ Gradio Chatbot ç»„ä»¶éœ€è¦ [[ç”¨æˆ·å†…å®¹, åŠ©æ‰‹å†…å®¹], ...] çš„äºŒç»´æ•°ç»„ã€‚
    """
    pairs = []
    for message in history:
        role = message.get("role")
        content = message.get("content", "")
        if role == "user":
            # æ–°å¼€ä¸€è½®å¯¹è¯ï¼ŒæŠŠç”¨æˆ·è¾“å…¥æ”¾åœ¨å·¦ä¾§
            pairs.append([content, ""])
        elif role == "assistant":
            if pairs:
                # å°†åŠ©æ‰‹å›å¤å¡«å……åˆ°ä¸Šä¸€æ¡ç”¨æˆ·æ¶ˆæ¯çš„å³ä¾§
                pairs[-1][1] = content
            else:
                # æŸäº›æç«¯æƒ…å†µä¸‹å†å²å¯èƒ½ä»¥ assistant å¼€å¤´ï¼Œè¿™é‡Œå…œåº•
                pairs.append(["", content])
        # å…¶ä»–è§’è‰²ï¼ˆå¦‚ systemï¼‰åœ¨å½“å‰ç•Œé¢ä¸­å¿½ç•¥
    return pairs


def format_session_status(session_id, history):
    """
    ç”Ÿæˆå½“å‰ä¼šè¯çš„çŠ¶æ€æ–‡æœ¬ï¼Œç”¨äº GUI é¡¶éƒ¨æç¤ºã€‚
    """
    total_messages = len(history)
    turns = sum(1 for msg in history if msg.get("role") == "assistant")
    return f"å½“å‰ä¼šè¯ï¼š{session_id} ï½œ è½®æ¬¡ï¼š{turns} ï½œ æ¶ˆæ¯æ•°ï¼š{total_messages}"


# --- 2. å‘½ä»¤è¡Œç•Œé¢ (CLI) å¯åŠ¨é€»è¾‘ ---
def start_cli():
    """å¯åŠ¨å‘½ä»¤è¡Œç‰ˆæœ¬çš„ AI åŠ©æ‰‹ã€‚"""
    # --- 1. ä½¿ç”¨ argparse è§£æå‘½ä»¤è¡Œå‚æ•° ---
    # åˆå­¦è€…æç¤ºï¼šargparse ä¼šè‡ªåŠ¨è§£æå‘½ä»¤è¡Œè¾“å…¥ã€ç”Ÿæˆå¸®åŠ©æ–‡æ¡£ï¼Œéå¸¸é€‚åˆå†™ CLI å·¥å…·
    parser = argparse.ArgumentParser(
        description="ä¸€ä¸ªæ”¯æŒå¤šç§è®°å¿†æ¨¡å¼å’Œæ–‡ä»¶æ³¨å…¥çš„å‘½ä»¤è¡Œ AI åŠ©æ‰‹ã€‚",
        # formatter_class å¯ä»¥è®©å¸®åŠ©ä¿¡æ¯æ›´å¥½åœ°æ˜¾ç¤ºé»˜è®¤å€¼
        formatter_class=argparse.ArgumentDefaultsHelpFormatter 
    )
    # å°†æ–‡ä»¶è·¯å¾„ä½œä¸ºå¯é€‰çš„ä½ç½®å‚æ•°ï¼Œè¿™æ ·ç”¨æˆ·å¯ä»¥ç›´æ¥æŠŠæ–‡æ¡£æ‹–å…¥ç»ˆç«¯åå›è½¦
    parser.add_argument(
        'file_path',
        nargs='?', # '?' è¡¨ç¤º 0 æˆ– 1 ä¸ªå‚æ•°ï¼Œä½¿å…¶æˆä¸ºå¯é€‰çš„ä½ç½®å‚æ•°
        default=None,
        help="æŒ‡å®šè¦åŠ è½½åˆ°ä¸Šä¸‹æ–‡ä¸­çš„æ–‡ä»¶è·¯å¾„ã€‚å¦‚æœæä¾›ï¼ŒAIä¼šå…ˆé˜…è¯»æ–‡ä»¶å†…å®¹ã€‚"
    )
    # å°†è®°å¿†æ¨¡å¼æ”¹ä¸ºå¯é€‰å‚æ•°ï¼Œä½¿ç”¨ -m æˆ– --mode
    parser.add_argument(
        '-m', '--mode',
        dest='memory_mode', # è§£æåçš„å‚æ•°å
        choices=['no', 'short', 'long'], # å…è®¸çš„å€¼
        default='short', # é»˜è®¤å€¼
        help="è®¾ç½®è®°å¿†æ¨¡å¼: 'no' (æ— è®°å¿†), 'short' (çŸ­æœŸä¼šè¯è®°å¿†), 'long' (é•¿æœŸæŒä¹…åŒ–è®°å¿†)ã€‚"
    )
    parser.add_argument(
        '--session',
        dest='session_id',
        default=DEFAULT_SESSION_ID,
        help="æŒ‡å®šä¼šè¯åç§°ï¼Œç”¨äºåŒºåˆ†ä¸åŒä¸»é¢˜çš„é•¿æœŸè®°å¿†ã€‚"
    )
    # parse_args() ä¼šæ ¹æ®ä¸Šé¢çš„å®šä¹‰è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    # normalize_session_id ä¼šç§»é™¤ä¸åˆæ³•å­—ç¬¦ï¼Œç¡®ä¿æ–‡ä»¶åå®‰å…¨
    session_id = memory_store.normalize_session_id(args.session_id)

    print("ğŸš€ æ­£åœ¨å¯åŠ¨å‘½ä»¤è¡Œ AI åŠ©æ‰‹...")
    print(f"ğŸ§  è®°å¿†æ¨¡å¼: {args.memory_mode}")
    print(f"ğŸ—‚ ä¼šè¯åç§°: {session_id}")

    # --- 2. åˆå§‹åŒ–æœåŠ¡å’Œä¼šè¯çŠ¶æ€ ---
    # è¿™é‡Œåªåˆ›å»ºä¸€æ¬¡æœåŠ¡å®ä¾‹ï¼Œé¿å…æ¯è½®å¯¹è¯é‡å¤å»ºç«‹ç½‘ç»œè¿æ¥
    ai_service = AIAssistantService(
        api_key=API_KEY,
        model_name=MODEL_NAME,
        api_url=API_URL,
        temperature=TEMPERATURE,
    )

    # æ ¹æ®è®°å¿†æ¨¡å¼åˆå§‹åŒ–å¯¹è¯å†å²
    # é•¿æœŸè®°å¿† => ä»ç£ç›˜è¯»å–å†å²ï¼›çŸ­æœŸ/æ— è®°å¿† => ç›´æ¥ä»ç©ºä¸Šä¸‹æ–‡å¼€å§‹
    if args.memory_mode == 'long':
        conversation_history = memory_store.load(session_id)
        if conversation_history:
            print(f"ğŸ—„ å·²åŠ è½½ä¼šè¯ '{session_id}' çš„å†å²æ¶ˆæ¯ï¼Œå…± {len(conversation_history)} æ¡ã€‚")
        else:
            print(f"ğŸ—„ ä¼šè¯ '{session_id}' æš‚æ— å†å²ï¼Œå°†ä»å¤´å¼€å§‹ã€‚")
    else:
        conversation_history = []
        print("AIå°åŠ©æ‰‹ï¼šä½ å¥½ï¼ä¸€ä¸ªæ–°çš„æ—…ç¨‹å¼€å§‹äº†ã€‚")

    file_context = None
    # æ£€æŸ¥ file_path æ˜¯å¦è¢«æä¾›ï¼Œå¹¶è¿›è¡Œç›¸åº”çš„å¤„ç†
    if args.file_path:
        # å¦‚æœ file_path æ˜¯ä¸€ä¸ªç›®å½•ï¼Œæç¤ºç”¨æˆ·ä½¿ç”¨æ‰¹é‡æ€»ç»“è„šæœ¬
        if os.path.isdir(args.file_path):
            print("ğŸ“ æ£€æµ‹åˆ°æ–‡ä»¶å¤¹è¾“å…¥ã€‚")
            print("æ­¤åŠŸèƒ½å·²ç§»è‡³æ–°è„šæœ¬ `note_process/batch_summarize.py`ã€‚")
            print("è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿è¡Œæ‰¹é‡æ€»ç»“åŠŸèƒ½:")
            print(f"   python note_process/batch_summarize.py \"{args.file_path}\"")
            sys.exit(0)
        # å¦‚æœ file_path æ˜¯ä¸€ä¸ªæ–‡ä»¶ï¼ŒåŠ è½½å…¶å†…å®¹
        elif os.path.isfile(args.file_path):
            try:
                with open(args.file_path, 'r', encoding='utf-8') as f:
                    file_context = f.read()
                print(f"ğŸ“ å·²åŠ è½½æ–‡ä»¶ '{os.path.basename(args.file_path)}'ã€‚ç°åœ¨æ‚¨å¯ä»¥åŸºäºè¯¥æ–‡ä»¶æé—®äº†ã€‚")
            except FileNotFoundError:
                print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {args.file_path}ã€‚è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
                sys.exit(1) # æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œç¨‹åºé€€å‡º
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
                sys.exit(1) # å…¶ä»–æ–‡ä»¶å¤„ç†é”™è¯¯ï¼Œç¨‹åºé€€å‡º
        # å¦‚æœ file_path æ—¢ä¸æ˜¯æ–‡ä»¶ä¹Ÿä¸æ˜¯ç›®å½•ï¼Œåˆ™æŠ¥é”™
        else:
            print(f"âŒ é”™è¯¯ï¼š'{args.file_path}' æ—¢ä¸æ˜¯æ–‡ä»¶ä¹Ÿä¸æ˜¯æ–‡ä»¶å¤¹ã€‚è¯·æä¾›æœ‰æ•ˆè·¯å¾„ã€‚")
            sys.exit(1)
    # ä¸»å¾ªç¯ï¼šä¸æ–­è¯»å–ç»ˆç«¯è¾“å…¥ï¼Œç›´åˆ°ç”¨æˆ·æ‰‹åŠ¨é€€å‡º
    while True:
        # ä½¿ç”¨ input() æ¥è·å–ä½ åœ¨ç»ˆç«¯è¾“å…¥çš„é—®é¢˜
        user_input = input("ä½ ï¼š")

        # è®¾ç½®é€€å‡ºæ¡ä»¶ï¼šå½“ç”¨æˆ·è¾“å…¥ç‰¹å®šå…³é”®è¯æ—¶ï¼Œä¿å­˜å†å²å¹¶é€€å‡ºå¾ªç¯
        # lower() å°†è¾“å…¥è½¬ä¸ºå°å†™ï¼Œä»è€Œæ”¯æŒ Quitã€QUIT ç­‰ä¸åŒå†™æ³•
        if user_input.lower() in ["quit", "exit","bye","goodbye","q","e"]:
            # ä»…åœ¨é•¿æœŸè®°å¿†æ¨¡å¼ä¸‹ä¿å­˜å†å²
            if args.memory_mode == 'long':
                memory_store.save(session_id, conversation_history)
            print("AIå°åŠ©æ‰‹ï¼šæœŸå¾…ä¸‹æ¬¡ä¸ä½ ç›¸è§ï¼")
            break

        # --- æ ¸å¿ƒä¿®æ”¹ï¼šåŠ¨æ€æ„å»ºç”¨æˆ·è¾“å…¥ ---
        # å¦‚æœå­˜åœ¨æ–‡ä»¶ä¸Šä¸‹æ–‡ï¼Œåˆ™å°†å…¶ä¸ç”¨æˆ·å½“å‰é—®é¢˜ç»„åˆ
        if file_context:
            # æ„å»ºä¸€ä¸ªåŒ…å«æ–‡ä»¶ä¸Šä¸‹æ–‡å’Œç”¨æˆ·é—®é¢˜çš„å¤åˆæç¤º
            # è¿™æ ·æ¨¡å‹ä¼šå…ˆé˜…è¯»æ–‡ä»¶å†…å®¹ï¼Œå†å›ç­”æœ€æ–°çš„é—®é¢˜
            final_input = f"""è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹æ¥å›ç­”æˆ‘çš„é—®é¢˜ã€‚
---
æ–‡æ¡£å†…å®¹:
{file_context}
---
æˆ‘çš„é—®é¢˜æ˜¯ï¼š{user_input}
"""
        else:
            # å¦‚æœæ²¡æœ‰æ–‡ä»¶ä¸Šä¸‹æ–‡ï¼Œåˆ™ç›´æ¥ä½¿ç”¨ç”¨æˆ·è¾“å…¥
            final_input = user_input

        # æ— è®ºä½•ç§æ¨¡å¼ï¼Œéƒ½å°†ç”¨æˆ·è¾“å…¥å­˜å…¥å®Œæ•´çš„å†å²è®°å½•ï¼Œä¿æŒä¸Šä¸‹æ–‡åŒæ­¥
        conversation_history.append({"role": "user", "content": final_input})

        # --- 3. æ ¹æ®è®°å¿†æ¨¡å¼å†³å®šå‘é€ç»™ AI çš„å†…å®¹ ---
        if args.memory_mode == 'no':
            # æ— è®°å¿†æ¨¡å¼ï¼šåªå‘é€åŒ…å«å½“å‰è¿™ä¸€æ¬¡è¾“å…¥çš„æ–°åˆ—è¡¨
            history_to_send = [conversation_history[-1]]
        else: # 'short' å’Œ 'long' æ¨¡å¼éƒ½ä½¿ç”¨çŸ­æœŸè®°å¿†
            # çŸ­æœŸ/é•¿æœŸè®°å¿†æ¨¡å¼ï¼šå‘é€åŒ…å«æ‰€æœ‰å†å²è®°å½•çš„å®Œæ•´åˆ—è¡¨
            # æ³¨æ„ï¼šå¯¹äº long æ¨¡å¼ï¼Œè¿™é‡Œä¸ conversation_history æ˜¯åŒä¸€ä¸ªåˆ—è¡¨
            history_to_send = conversation_history

        # è°ƒç”¨ç”Ÿæˆå™¨å‡½æ•°ï¼Œå¹¶è¿­ä»£æ‰“å°ç»“æœ
        print(f"AIåŠ©æ‰‹ï¼š", end="")
        full_response = ""
        has_error = False
        # è°ƒç”¨ AI æœåŠ¡å®ä¾‹çš„æ–¹æ³•
        for chunk in ai_service.stream_chat_completion(history_to_send):
            # æ£€æŸ¥è¿”å›çš„ç‰‡æ®µä¸­æ˜¯å¦åŒ…å«é”™è¯¯ä¿¡æ¯
            if "ç½‘ç»œé”™è¯¯" in chunk or "æœªçŸ¥é”™è¯¯" in chunk:
                has_error = True
            full_response += chunk
            # flush=True å¼ºåˆ¶åˆ·æ–°è¾“å‡ºç¼“å†²åŒºï¼Œç¡®ä¿å†…å®¹èƒ½è¢«ç«‹å³æ˜¾ç¤º
            print(chunk, end="", flush=True)
        print() # ç»“æŸæ—¶æ¢è¡Œ

        # æ— è®ºä½•ç§æ¨¡å¼ï¼Œéƒ½å°†AIçš„å›ç­”ä¹Ÿå­˜å…¥å®Œæ•´çš„å†å²è®°å½•
        # (ç¡®ä¿ä¸ä¼šæŠŠé”™è¯¯ä¿¡æ¯ä¹Ÿè®°ä¸‹æ¥), ä»¥å¤‡å°†æ¥ä¿å­˜
        if not has_error:
            conversation_history.append({"role": "assistant", "content": full_response})
            if args.memory_mode == 'long':
                memory_store.save(session_id, conversation_history)
        
        print("\n" + "-"*30) #æ‰“å°åˆ†éš”çº¿ï¼Œå¹¶åœ¨å‰é¢åŠ ä¸€ä¸ªæ¢è¡Œä»¥æ”¹å–„é—´è·

# --- 3. å›¾å½¢ç”¨æˆ·ç•Œé¢ (GUI) å¯åŠ¨é€»è¾‘ ---
def start_gui():
    """å¯åŠ¨ Gradio å›¾å½¢ç”¨æˆ·ç•Œé¢ã€‚"""
    print("ğŸš€ æ­£åœ¨å¯åŠ¨ Gradio å›¾å½¢ç•Œé¢...")

    # --- åˆå§‹åŒ– AI æœåŠ¡ ---
    ai_service = AIAssistantService(
        api_key=API_KEY,
        model_name=MODEL_NAME,
        api_url=API_URL,
        temperature=TEMPERATURE,
    )

    # --- å‡†å¤‡é»˜è®¤ä¼šè¯ ---
    initial_session = memory_store.normalize_session_id(DEFAULT_SESSION_ID)
    initial_history = memory_store.load(initial_session)
    initial_pairs = history_to_chatbot_pairs(initial_history)
    initial_status = format_session_status(initial_session, initial_history)
    print(f"ğŸ—„ GUI ä¼šè¯ '{initial_session}' å·²åŠ è½½ {len(initial_history)} æ¡æ¶ˆæ¯ã€‚")

    # --- ä¸º Gradio UI ç¼–å†™çš„æ¥å£å‡½æ•° ---
    def chat_response(user_input, chatbot_history, conversation_state, session_id):
        """å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œå¹¶æµå¼è¿”å›AIå“åº”ã€‚"""
        session_id = memory_store.normalize_session_id(session_id)
        # å°†ç”¨æˆ·è¾“å…¥è¿½åŠ åˆ°å†å²åˆ—è¡¨ï¼Œä¿å­˜ä¸º {"role": "user", "content": "..."} çš„æ ¼å¼
        conversation_state.append({"role": "user", "content": user_input})
        # åŒæ­¥æ›´æ–°ç•Œé¢ç»„ä»¶ï¼Œè®©ç”¨æˆ·è¾“å…¥ç«‹å³å‡ºç°åœ¨èŠå¤©çª—å£é‡Œ
        chatbot_history.append([user_input, ""])
        yield (
            chatbot_history,
            conversation_state,
            gr.update(value=format_session_status(session_id, conversation_state)),
        )

        # æµå¼è·å–AIå›å¤ï¼šæ¨¡å‹è¾“å‡ºè¢«æ‹†æˆå¤šæ¬¡å›è°ƒï¼Œèƒ½å¤Ÿæ¨¡æ‹Ÿå®æ—¶æ‰“å°çš„æ•ˆæœ
        full_response = ""
        has_error = False
        for chunk in ai_service.stream_chat_completion(conversation_state):
            if "ç½‘ç»œé”™è¯¯" in chunk or "æœªçŸ¥é”™è¯¯" in chunk:
                has_error = True
            full_response += chunk
            # æ›´æ–°å½“å‰è½®çš„â€œåŠ©æ‰‹å›ç­”â€éƒ¨åˆ†ï¼Œè®©ç”¨æˆ·çœ‹åˆ°å®æ—¶ç”Ÿæˆçš„å†…å®¹
            chatbot_history[-1][1] = full_response
            yield (
                chatbot_history,
                conversation_state,
                gr.update(value=format_session_status(session_id, conversation_state)),
            )

        if not has_error:
            # å°†åŠ©æ‰‹å›å¤è¿½åŠ åˆ°å†å²ä¸­ï¼Œå¹¶ç«‹å³å†™å…¥ç£ç›˜æ–‡ä»¶
            conversation_state.append({"role": "assistant", "content": full_response})
            memory_store.save(session_id, conversation_state)

        yield (
            chatbot_history,
            conversation_state,
            gr.update(value=format_session_status(session_id, conversation_state)),
        )

    def switch_session(requested_session, conversation_history, current_session_id):
        """
        åˆ‡æ¢åˆ°æ–°çš„ä¼šè¯ï¼šä¿å­˜å½“å‰å†å²åï¼ŒåŠ è½½ç›®æ ‡ä¼šè¯å¹¶åˆ·æ–°ç•Œé¢ã€‚
        """
        current_session_id = memory_store.normalize_session_id(current_session_id)
        if conversation_history:
            # ç¦»å¼€æ—§ä¼šè¯å‰å…ˆä¿å­˜ï¼Œé¿å…æœªæäº¤çš„å¯¹è¯è¢«è¦†ç›–
            memory_store.save(current_session_id, conversation_history)

        # åŠ è½½ç›®æ ‡ä¼šè¯ï¼Œå¦‚æœè¿˜ä¸å­˜åœ¨åˆ™ä¼šè¿”å›ç©ºå†å²
        new_session = memory_store.normalize_session_id(requested_session)
        new_history = memory_store.load(new_session)
        print(f"ğŸ—„ å·²åˆ‡æ¢åˆ°ä¼šè¯ '{new_session}'ï¼Œå…± {len(new_history)} æ¡æ¶ˆæ¯ã€‚")

        chatbot_pairs = history_to_chatbot_pairs(new_history)
        status_text = format_session_status(new_session, new_history)

        return (
            gr.update(value=new_session),
            gr.update(value=chatbot_pairs),
            new_history,
            new_session,
            gr.update(value=status_text),
        )

    # --- æ„å»º Gradio ç•Œé¢ ---
    with gr.Blocks(title="AI åŠ©æ‰‹") as app:
        # gr.State åœ¨æœåŠ¡å™¨ç«¯ä¿å­˜çŠ¶æ€ï¼Œç›¸å½“äºâ€œéšè—å˜é‡â€ï¼Œä¸ä¼šç›´æ¥å±•ç¤ºç»™ç”¨æˆ·
        conversation_state = gr.State(value=list(initial_history))
        session_state = gr.State(value=initial_session)

        gr.Markdown("# ğŸ¤– AI åŠ©æ‰‹")
        gr.Markdown("ä¸€ä¸ªç”±é˜¿é‡Œé€šä¹‰åƒé—®é©±åŠ¨çš„æ™ºèƒ½åŠ©æ‰‹ã€‚")

        with gr.Row():
            session_input = gr.Textbox(
                label="ä¼šè¯åç§°",
                value=initial_session,
                placeholder="ä¾‹å¦‚ï¼šå·¥ä½œ",
                scale=5,
            )
            load_button = gr.Button("åˆ‡æ¢ä¼šè¯", variant="secondary", scale=1)

        # ä¼šè¯çŠ¶æ€å±•ç¤ºå½“å‰ä¼šè¯åã€è½®æ¬¡ï¼Œå¸®åŠ©ç”¨æˆ·ç¡®è®¤ä¸Šä¸‹æ–‡
        session_status = gr.Markdown(initial_status)

        # Chatbot ç»„ä»¶ç”¨æ¥æ¸²æŸ“èŠå¤©æ°”æ³¡ï¼Œåˆå§‹å€¼ä¸ºå†å²è®°å½•
        chatbot = gr.Chatbot(label="é€šä¹‰åƒé—®", height=500, value=initial_pairs)

        with gr.Row():
            txt_input = gr.Textbox(show_label=False, lines=3, placeholder="è¯¢é—®ä»»ä½•é—®é¢˜", scale=8)
            btn_submit = gr.Button("å‘é€", variant="primary", scale=1)

        # --- ç»‘å®šäº‹ä»¶ ---
        # ç‚¹å‡»â€œåˆ‡æ¢ä¼šè¯â€æ—¶å…ˆä¿å­˜å½“å‰å†å²ï¼Œå†è½½å…¥ç›®æ ‡ä¼šè¯
        load_button.click(
            switch_session,
            inputs=[session_input, conversation_state, session_state],
            outputs=[session_input, chatbot, conversation_state, session_state, session_status],
        )

        submit_inputs = [txt_input, chatbot, conversation_state, session_state]
        submit_outputs = [chatbot, conversation_state, session_status]
        # æ–‡æœ¬æ¡†å›è½¦ã€æŒ‰é’®ç‚¹å‡»å…±ç”¨åŒä¸€å¥—é€»è¾‘
        txt_input.submit(chat_response, submit_inputs, submit_outputs).then(lambda: "", [], [txt_input])
        btn_submit.click(chat_response, submit_inputs, submit_outputs).then(lambda: "", [], [txt_input])

    # å¯åŠ¨Gradioåº”ç”¨ï¼Œå¯åŠ¨åä¼šåœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ä¸€ä¸ªæ–°é¡µé¢
    app.launch()

# --- 4. ä¸»ç¨‹åºæ‰§è¡Œå…¥å£ ---
# ä¸‹é¢çš„ä»£ç åªæœ‰åœ¨ç›´æ¥è¿è¡Œ `python ai_assistant.py` æ—¶æ‰ä¼šæ‰§è¡Œ
if __name__ == "__main__":
    # ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦è¦å¯åŠ¨ GUI æ¨¡å¼
    if '--gui' in sys.argv:
        start_gui()
    else:
        # å¦åˆ™ï¼Œå¯åŠ¨é»˜è®¤çš„å‘½ä»¤è¡Œæ¨¡å¼
        # start_cli å‡½æ•°å†…éƒ¨ä¼šä½¿ç”¨ argparse å¤„ç†æ‰€æœ‰ç›¸å…³çš„å‘½ä»¤è¡Œå‚æ•°
        start_cli()
