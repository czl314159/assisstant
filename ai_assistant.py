"""
è„šæœ¬åç§°: AI åŠ©æ‰‹ (ai_assistant.py)

åŠŸèƒ½æè¿°:
    è¿™æ˜¯AIåŠ©æ‰‹çš„äº¤äº’å±‚(é—¨é¢)ã€‚
    å®ƒè´Ÿè´£å¯åŠ¨å’Œç®¡ç†å‘½ä»¤è¡Œç•Œé¢ (CLI) å’Œå›¾å½¢ç”¨æˆ·ç•Œé¢ (Web UI)ï¼Œ
    å¹¶å°†æ‰€æœ‰æ ¸å¿ƒçš„AIé€»è¾‘å¤„ç†å§”æ‰˜ç»™ `orchestrator.py`ã€‚

ä½¿ç”¨æ–¹æ³•:
    ä¸ä¹‹å‰å®Œå…¨ç›¸åŒã€‚
    - CLI: `python ai_assistant.py`
    - GUI: `python ai_assistant.py --gui`
"""
import os
import sys
import gradio as gr
import argparse
from dotenv import load_dotenv

# æ ¸å¿ƒå˜åŒ–ï¼šå¯¼å…¥æ–°çš„è°ƒåº¦å™¨
from orchestrator import Orchestrator

# --- è¾…åŠ©å‡½æ•° (UIç›¸å…³ï¼Œä¿ç•™åœ¨æ­¤) ---
def history_to_chatbot_pairs(history):
    """
    å°†å®Œæ•´çš„æ¶ˆæ¯å†å²è½¬æ¢ä¸º Chatbot ç»„ä»¶éœ€è¦çš„ [user, assistant] åˆ—è¡¨ã€‚
    """
    pairs = []
    for message in history:
        role = message.get("role")
        content = message.get("content", "")
        if role == "user":
            pairs.append([content, ""])
        elif role == "assistant":
            if pairs:
                pairs[-1][1] = content
            else:
                pairs.append(["", content])
    return pairs

def format_session_status(session_id, history):
    """
    ç”Ÿæˆå½“å‰ä¼šè¯çš„çŠ¶æ€æ–‡æœ¬ï¼Œç”¨äº GUI é¡¶éƒ¨æç¤ºã€‚
    """
    total_messages = len(history)
    turns = sum(1 for msg in history if msg.get("role") == "assistant")
    return f"å½“å‰ä¼šè¯ï¼š{session_id} ï½œ è½®æ¬¡ï¼š{turns} ï½œ æ¶ˆæ¯æ•°ï¼š{total_messages}"

# --- 1. é…ç½®ç¨‹åºæ‰€éœ€çš„å˜é‡ ---
load_dotenv()
API_KEY = os.getenv("ALIYUN_API_KEY") 
if not API_KEY: 
    print("é”™è¯¯ï¼šæœªæ‰¾åˆ°ALIYUN_API_KEYç¯å¢ƒå˜é‡ï¼") 
    print("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„APIå¯†é’¥") 
    exit(1) 

API_URL = os.getenv("ALIYUN_API_URL")
if not API_URL:
    print("é”™è¯¯ï¼šæœªæ‰¾åˆ°ALIYUN_API_URLç¯å¢ƒå˜é‡ï¼")
    print("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„APIåœ°å€")
    exit(1)

MODEL_NAME = os.getenv("ALIYUN_MODEL_NAME")
if not MODEL_NAME:
    print("è­¦å‘Šï¼šæœªæ‰¾åˆ°ALIYUN_MODEL_NAMEç¯å¢ƒå˜é‡ï¼")
    print("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„æ¨¡å‹åç§°")
    exit(1)

MEMORY_ROOT = os.getenv("MEMORY_ROOT", "data/sessions")
DEFAULT_SESSION_ID = "default"
TEMPERATURE = float(os.getenv("TEMPERATURE",0.5))

# --- 2. åˆå§‹åŒ–æ ¸å¿ƒè°ƒåº¦å™¨ ---
# è¿™æ˜¯å…³é”®ä¸€æ­¥ï¼šåˆ›å»ºOrchestratorçš„å•ä¸€å®ä¾‹ï¼Œå®ƒå°†ç®¡ç†æ‰€æœ‰åç«¯é€»è¾‘
orchestrator = Orchestrator(
    api_key=API_KEY,
    model_name=MODEL_NAME,
    api_url=API_URL,
    temperature=TEMPERATURE,
    memory_root=MEMORY_ROOT
)

# --- 3. å‘½ä»¤è¡Œç•Œé¢ (CLI) å¯åŠ¨é€»è¾‘ ---
def start_cli():
    """å¯åŠ¨å‘½ä»¤è¡Œç‰ˆæœ¬çš„ AI åŠ©æ‰‹ (ç®€åŒ–ç‰ˆ)ã€‚"""
    parser = argparse.ArgumentParser(
        description="ä¸€ä¸ªæ”¯æŒå¤šç§è®°å¿†æ¨¡å¼å’Œæ–‡ä»¶æ³¨å…¥çš„å‘½ä»¤è¡Œ AI åŠ©æ‰‹ã€‚",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter 
    )
    parser.add_argument(
        'file_path',
        nargs='?',
        default=None,
        help="æŒ‡å®šè¦åŠ è½½åˆ°ä¸Šä¸‹æ–‡ä¸­çš„æ–‡ä»¶è·¯å¾„ã€‚å¦‚æœæä¾›ï¼ŒAIä¼šå…ˆé˜…è¯»æ–‡ä»¶å†…å®¹ã€‚"
    )
    parser.add_argument(
        '-m', '--mode',
        dest='memory_mode',
        choices=['no', 'short', 'long'],
        default='short',
        help="è®¾ç½®è®°å¿†æ¨¡å¼: 'no' (æ— è®°å¿†), 'short' (çŸ­æœŸä¼šè¯è®°å¿†), 'long' (é•¿æœŸæŒä¹…åŒ–è®°å¿†)ã€‚"
    )
    parser.add_argument(
        '--session',
        dest='session_id',
        default=DEFAULT_SESSION_ID,
        help="æŒ‡å®šä¼šè¯åç§°ï¼Œç”¨äºåŒºåˆ†ä¸åŒä¸»é¢˜çš„é•¿æœŸè®°å¿†ã€‚"
    )
    args = parser.parse_args()
    session_id = orchestrator.normalize_session_id(args.session_id)

    print("ğŸš€ æ­£åœ¨å¯åŠ¨å‘½ä»¤è¡Œ AI åŠ©æ‰‹...")
    print(f"ğŸ§  è®°å¿†æ¨¡å¼: {args.memory_mode}")
    print(f"ğŸ—‚ ä¼šè¯åç§°: {session_id}")

    if args.memory_mode == 'long':
        conversation_history = orchestrator.load_memory(session_id)
        if conversation_history:
            print(f"ğŸ—„ å·²åŠ è½½ä¼šè¯ '{session_id}' çš„å†å²æ¶ˆæ¯ï¼Œå…± {len(conversation_history)} æ¡ã€‚")
        else:
            print(f"ğŸ—„ ä¼šè¯ '{session_id}' æš‚æ— å†å²ï¼Œå°†ä»å¤´å¼€å§‹ã€‚")
    else:
        conversation_history = []
        print("AIå°åŠ©æ‰‹ï¼šä½ å¥½ï¼ä¸€ä¸ªæ–°çš„æ—…ç¨‹å¼€å§‹äº†ã€‚")

    file_context = None
    if args.file_path:
        if os.path.isdir(args.file_path):
            print("ğŸ“ æ£€æµ‹åˆ°æ–‡ä»¶å¤¹è¾“å…¥ã€‚")
            print("æ­¤åŠŸèƒ½å·²ç§»è‡³æ–°è„šæœ¬ `note_process/batch_summarize.py`ã€‚")
            print(f"   python note_process/batch_summarize.py \"{args.file_path}\"")
            sys.exit(0)
        elif os.path.isfile(args.file_path):
            try:
                with open(args.file_path, 'r', encoding='utf-8') as f:
                    file_context = f.read()
                print(f"ğŸ“ å·²åŠ è½½æ–‡ä»¶ '{os.path.basename(args.file_path)}'ã€‚ç°åœ¨æ‚¨å¯ä»¥åŸºäºè¯¥æ–‡ä»¶æé—®äº†ã€‚")
            except FileNotFoundError:
                print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {args.file_path}ã€‚è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
                sys.exit(1)
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
                sys.exit(1)
        else:
            print(f"âŒ é”™è¯¯ï¼š'{args.file_path}' æ—¢ä¸æ˜¯æ–‡ä»¶ä¹Ÿä¸æ˜¯æ–‡ä»¶å¤¹ã€‚è¯·æä¾›æœ‰æ•ˆè·¯å¾„ã€‚")
            sys.exit(1)

    while True:
        user_input = input("ä½ ï¼š")
        if user_input.lower() in ["quit", "exit", "bye", "goodbye", "q", "e"]:
            if args.memory_mode == 'long':
                orchestrator.save_memory(session_id, conversation_history)
            print("AIå°åŠ©æ‰‹ï¼šæœŸå¾…ä¸‹æ¬¡ä¸ä½ ç›¸è§ï¼")
            break

        # æ ¸å¿ƒå˜åŒ–ï¼šå°†æ‰€æœ‰å·¥ä½œå§”æ‰˜ç»™ orchestrator
        conversation_history = orchestrator.handle_cli_request(
            user_input=user_input,
            conversation_history=conversation_history,
            memory_mode=args.memory_mode,
            session_id=session_id,
            file_context=file_context
        )
        
        print("\n" + "-"*30)

# --- 4. å›¾å½¢ç”¨æˆ·ç•Œé¢ (GUI) å¯åŠ¨é€»è¾‘ ---
def start_gui():
    """å¯åŠ¨ Gradio å›¾å½¢ç”¨æˆ·ç•Œé¢ (ç®€åŒ–ç‰ˆ)ã€‚"""
    print("ğŸš€ æ­£åœ¨å¯åŠ¨ Gradio å›¾å½¢ç•Œé¢...")

    initial_session = orchestrator.normalize_session_id(DEFAULT_SESSION_ID)
    initial_history = orchestrator.load_memory(initial_session)
    initial_pairs = history_to_chatbot_pairs(initial_history)
    initial_status = format_session_status(initial_session, initial_history)
    print(f"ğŸ—„ GUI ä¼šè¯ '{initial_session}' å·²åŠ è½½ {len(initial_history)} æ¡æ¶ˆæ¯ã€‚")

    def chat_response(user_input, chatbot_history, conversation_state, session_id):
        """Gradioçš„å“åº”å‡½æ•°ï¼Œç°åœ¨æ˜¯ä¸€ä¸ªå›´ç»•Orchestratorçš„è–„åŒ…è£…ã€‚"""
        # æ›´æ–°æœ¬åœ°çŠ¶æ€å’ŒUI
        # ç”¨æˆ·æ¶ˆæ¯å°†ç”± orchestrator æ·»åŠ åˆ° historyï¼Œæ­¤å¤„ä¸å†é‡å¤æ·»åŠ 
        chatbot_history.append([user_input, ""])
        yield (chatbot_history, conversation_state, gr.update(value=format_session_status(session_id, conversation_state)))

        # æ ¸å¿ƒå˜åŒ–ï¼šå°†æµå¼å“åº”çš„é€»è¾‘å§”æ‰˜ç»™ orchestrator
        full_response = ""
        for response_chunk in orchestrator.handle_gui_request(user_input, conversation_state, session_id):
            full_response = response_chunk
            chatbot_history[-1][1] = full_response
            yield (chatbot_history, conversation_state, gr.update(value=format_session_status(session_id, conversation_state)))

    def switch_session(requested_session, conversation_history, current_session_id):
        """ä¼šè¯åˆ‡æ¢ï¼Œå§”æ‰˜ç»™ orchestratorã€‚"""
        new_session, new_history = orchestrator.switch_gui_session(
            requested_session, conversation_history, current_session_id
        )
        chatbot_pairs = history_to_chatbot_pairs(new_history)
        status_text = format_session_status(new_session, new_history)
        return (gr.update(value=new_session), gr.update(value=chatbot_pairs), new_history, new_session, gr.update(value=status_text))

    with gr.Blocks(title="AI åŠ©æ‰‹") as app:
        conversation_state = gr.State(value=list(initial_history))
        session_state = gr.State(value=initial_session)

        gr.Markdown("# ğŸ¤– AI åŠ©æ‰‹")
        gr.Markdown("ä¸€ä¸ªç”±é˜¿é‡Œé€šä¹‰åƒé—®é©±åŠ¨çš„æ™ºèƒ½åŠ©æ‰‹ã€‚")

        with gr.Row():
            session_input = gr.Textbox(
                label="ä¼šè¯åç§°",
                value=initial_session,
                placeholder="ä¾‹å¦‚ï¼šå·¥ä½œ",
                scale=5,
            )
            load_button = gr.Button("åˆ‡æ¢ä¼šè¯", variant="secondary", scale=1)

        session_status = gr.Markdown(initial_status)
        chatbot = gr.Chatbot(label="é€šä¹‰åƒé—®", height=500, value=initial_pairs)

        with gr.Row():
            txt_input = gr.Textbox(show_label=False, lines=3, placeholder="è¯¢é—®ä»»ä½•é—®é¢˜", scale=8)
            btn_submit = gr.Button("å‘é€", variant="primary", scale=1)

        load_button.click(
            switch_session,
            inputs=[session_input, conversation_state, session_state],
            outputs=[session_input, chatbot, conversation_state, session_state, session_status],
        )

        submit_inputs = [txt_input, chatbot, conversation_state, session_state]
        submit_outputs = [chatbot, conversation_state, session_status]
        txt_input.submit(chat_response, submit_inputs, submit_outputs).then(lambda: "", [], [txt_input])
        btn_submit.click(chat_response, submit_inputs, submit_outputs).then(lambda: "", [], [txt_input])

    app.launch()

# --- 5. ä¸»ç¨‹åºæ‰§è¡Œå…¥å£ ---
if __name__ == "__main__":
    if '--gui' in sys.argv:
        start_gui()
    else:
        start_cli()
