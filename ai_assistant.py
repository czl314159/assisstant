"""
è„šæœ¬åç§°: AI åŠ©æ‰‹ (ai_assistant.py)

åŠŸèƒ½æè¿°:
    è¿™æ˜¯ä¸€ä¸ªå¤šåŠŸèƒ½çš„ AI èŠå¤©æœºå™¨äººï¼Œæ”¯æŒå‘½ä»¤è¡Œç•Œé¢ (CLI) å’Œå›¾å½¢ç”¨æˆ·ç•Œé¢ (Web UI)ã€‚
    å®ƒé€šè¿‡é˜¿é‡Œäº‘çš„é€šä¹‰åƒé—®æ¨¡å‹æä¾›æ™ºèƒ½å¯¹è¯æœåŠ¡ï¼Œå¹¶æ”¯æŒæµå¼å“åº”ä»¥å®ç°å®æ—¶äº¤äº’ã€‚
    CLI æ¨¡å¼ä¸‹å…·æœ‰å¯¹è¯å†å²æŒä¹…åŒ–åŠŸèƒ½ï¼ŒWeb UI æ¨¡å¼åˆ™æä¾›æ›´å‹å¥½çš„å¯è§†åŒ–äº¤äº’ã€‚
    æ­¤å¤–ï¼ŒCLI æ¨¡å¼è¿˜æ”¯æŒå°†å¤–éƒ¨æ–‡ä»¶å†…å®¹æ³¨å…¥åˆ°å¯¹è¯ä¸Šä¸‹æ–‡ä¸­ï¼Œä»¥ä¾¿ AI è¿›è¡Œæ›´æ·±å…¥çš„åˆ†æå’Œè®¨è®ºã€‚

    æ³¨æ„ï¼šåŸæœ‰çš„æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹åŠŸèƒ½å·²è¢«ç§»è‡³ `note_process/batch_summarize.py` è„šæœ¬ã€‚

ä½¿ç”¨æ–¹æ³•:
    1.  **CLI æ¨¡å¼ (é»˜è®¤çŸ­æœŸè®°å¿†)**:
        åœ¨ç»ˆç«¯ä¸­è¿è¡Œ: `python ai_assistant.py`
        -   ç›´æ¥è¾“å…¥é—®é¢˜ä¸ AI å¯¹è¯ã€‚
        -   è¾“å…¥ "quit", "exit", "bye", "goodbye" ä¹‹ä¸€å³å¯é€€å‡ºã€‚

    2.  **CLI æ¨¡å¼ (é€‰æ‹©è®°å¿†ç­–ç•¥ / ä¼šè¯)**:
        -   é•¿æœŸè®°å¿†: `python ai_assistant.py --mode long`
        -   ç¦ç”¨è®°å¿†: `python ai_assistant.py --mode no`
        -   æŒ‡å®šä¼šè¯: `python ai_assistant.py --mode long --session å·¥ä½œ`
            (ä¸åŒä¼šè¯çš„å†å²ä¼šåˆ†åˆ«ä¿å­˜åœ¨ç‹¬ç«‹æ–‡ä»¶ä¸­)

    3.  **CLI æ¨¡å¼ (å¸¦æ–‡ä»¶æ³¨å…¥)**:
        åœ¨ç»ˆç«¯ä¸­è¿è¡Œ: `python ai_assistant.py <æ–‡ä»¶è·¯å¾„> [å…¶å®ƒå‚æ•°]`
        -   ä¾‹å¦‚: `python ai_assistant.py notes/summary.md --mode long`
        -   AI ä¼šå…ˆé˜…è¯»æ–‡ä»¶å†…å®¹ï¼Œå†ç­‰å¾…ä½ çš„æé—®ã€‚

    4.  **Web UI æ¨¡å¼**:
        åœ¨ç»ˆç«¯ä¸­è¿è¡Œ: `python ai_assistant.py --gui`
        -   å¯åŠ¨åŸºäº Gradio çš„ Web ç•Œé¢ï¼Œå¯åœ¨æµè§ˆå™¨ä¸­ä¸ AI äº¤äº’ã€‚

é…ç½®:
    -   **API å¯†é’¥**: å¿…é¡»åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ `.env` æ–‡ä»¶ä¸­è®¾ç½® `ALIYUN_API_KEY` ç¯å¢ƒå˜é‡ã€‚
        ä¾‹å¦‚: `ALIYUN_API_KEY="your_api_key_here"`
    -   **ä»£ç†**: å¦‚æœéœ€è¦ï¼Œå¯ä»¥åœ¨ `PROXY_URL` å˜é‡ä¸­é…ç½®ä»£ç†æœåŠ¡å™¨åœ°å€ã€‚
    -   **å†å²è®°å½•**: é•¿æœŸè®°å¿†æ¨¡å¼ä¼šå°†å†å²ä¿å­˜åœ¨ `data/sessions/` ç›®å½•ä¸‹ï¼ˆå¯é€šè¿‡ `MEMORY_ROOT` è°ƒæ•´ï¼‰ã€‚

ä¾èµ–:
    -   `requests`
    -   `gradio`
    -   `python-dotenv`
    -   `json`
    -   `os`
    -   `sys`

æ³¨æ„äº‹é¡¹:
    -   Web UI æ¨¡å¼ä¸‹çš„å¯¹è¯å†å²ä¸ä¼šè¢«æŒä¹…åŒ–ä¿å­˜ã€‚
    -   ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–åº“ (`pip install -r requirements.txt`)ã€‚
"""
import os
import sys
import gradio as gr
import argparse
from dotenv import load_dotenv
# ä» note_process æ–‡ä»¶å¤¹ä¸‹çš„ ai_service.py æ–‡ä»¶ä¸­å¯¼å…¥ AIAssistantService ç±»
from ai_service import AIAssistantService
from memory_store import MemoryStore

load_dotenv() # åœ¨æ‰€æœ‰ä»£ç ä¹‹å‰ï¼Œè¿è¡Œè¿™ä¸ªå‡½æ•°ï¼Œå®ƒä¼šè‡ªåŠ¨åŠ è½½.envæ–‡ä»¶

# --- 1. é…ç½®ç¨‹åºæ‰€éœ€çš„å˜é‡ ---

# æç¤ºï¼šä¸ºäº†å®‰å…¨ï¼Œæœ€å¥½å°†APIå¯†é’¥å­˜å‚¨åœ¨ç¯å¢ƒå˜é‡ä¸­.å¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯å¹¶é€€å‡ºã€‚
API_KEY = os.getenv("ALIYUN_API_KEY") 
if not API_KEY: 
    print("é”™è¯¯ï¼šæœªæ‰¾åˆ°ALIYUN_API_KEYç¯å¢ƒå˜é‡ï¼") 
    print("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„APIå¯†é’¥") 
    exit(1) 

API_URL = os.getenv("ALIYUN_API_URL")
if not API_URL:
    print("é”™è¯¯ï¼šæœªæ‰¾åˆ°ALIYUN_API_URLç¯å¢ƒå˜é‡ï¼")
    print("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„APIåœ°å€")
    exit(1)

MODEL_NAME = os.getenv("ALIYUN_MODEL_NAME")
if not MODEL_NAME:
    print("è­¦å‘Šï¼šæœªæ‰¾åˆ°ALIYUN_MODEL_NAMEç¯å¢ƒå˜é‡ï¼")
    print("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„æ¨¡å‹åç§°")
    exit(1)

MEMORY_ROOT = os.getenv("MEMORY_ROOT", "data/sessions")
DEFAULT_SESSION_ID = "default"
TEMPERATURE = float(os.getenv("TEMPERATURE",0.5))

memory_store = MemoryStore(root_dir=MEMORY_ROOT)

# --- 3. æ ¸å¿ƒåŠŸèƒ½å°è£… ---

# --- 4. å‘½ä»¤è¡Œç•Œé¢ (CLI) å¯åŠ¨é€»è¾‘ ---
def start_cli():
    """å¯åŠ¨å‘½ä»¤è¡Œç‰ˆæœ¬çš„ AI åŠ©æ‰‹ã€‚"""
    # --- 1. ä½¿ç”¨ argparse è§£æå‘½ä»¤è¡Œå‚æ•° ---
    parser = argparse.ArgumentParser(
        description="ä¸€ä¸ªæ”¯æŒå¤šç§è®°å¿†æ¨¡å¼å’Œæ–‡ä»¶æ³¨å…¥çš„å‘½ä»¤è¡Œ AI åŠ©æ‰‹ã€‚",
        # formatter_class å¯ä»¥è®©å¸®åŠ©ä¿¡æ¯æ›´å¥½åœ°æ˜¾ç¤ºé»˜è®¤å€¼
        formatter_class=argparse.ArgumentDefaultsHelpFormatter 
    )
    # å°†æ–‡ä»¶è·¯å¾„ä½œä¸ºå¯é€‰çš„ä½ç½®å‚æ•°ï¼Œå…è®¸ç”¨æˆ·ç›´æ¥åœ¨è„šæœ¬ååæä¾›
    parser.add_argument(
        'file_path',
        nargs='?', # '?' è¡¨ç¤º 0 æˆ– 1 ä¸ªå‚æ•°ï¼Œä½¿å…¶æˆä¸ºå¯é€‰çš„ä½ç½®å‚æ•°
        default=None,
        help="æŒ‡å®šè¦åŠ è½½åˆ°ä¸Šä¸‹æ–‡ä¸­çš„æ–‡ä»¶è·¯å¾„ã€‚å¦‚æœæä¾›ï¼ŒAIä¼šå…ˆé˜…è¯»æ–‡ä»¶å†…å®¹ã€‚"
    )
    # å°†è®°å¿†æ¨¡å¼æ”¹ä¸ºå¯é€‰å‚æ•°ï¼Œä½¿ç”¨ -m æˆ– --mode
    parser.add_argument(
        '-m', '--mode',
        dest='memory_mode', # è§£æåçš„å‚æ•°å
        choices=['no', 'short', 'long'], # å…è®¸çš„å€¼
        default='short', # é»˜è®¤å€¼
        help="è®¾ç½®è®°å¿†æ¨¡å¼: 'no' (æ— è®°å¿†), 'short' (çŸ­æœŸä¼šè¯è®°å¿†), 'long' (é•¿æœŸæŒä¹…åŒ–è®°å¿†)ã€‚"
    )
    parser.add_argument(
        '--session',
        dest='session_id',
        default=DEFAULT_SESSION_ID,
        help="æŒ‡å®šä¼šè¯åç§°ï¼Œç”¨äºåŒºåˆ†ä¸åŒä¸»é¢˜çš„é•¿æœŸè®°å¿†ã€‚"
    )
    args = parser.parse_args() # ç›´æ¥è§£ææ‰€æœ‰å‚æ•°
    session_id = args.session_id.strip() or DEFAULT_SESSION_ID

    print("ğŸš€ æ­£åœ¨å¯åŠ¨å‘½ä»¤è¡Œ AI åŠ©æ‰‹...")
    print(f"ğŸ§  è®°å¿†æ¨¡å¼: {args.memory_mode}")
    print(f"ğŸ—‚ ä¼šè¯åç§°: {session_id}")

    # --- 2. åˆå§‹åŒ–æœåŠ¡å’Œä¼šè¯çŠ¶æ€ ---
    ai_service = AIAssistantService(
        api_key=API_KEY,
        model_name=MODEL_NAME,
        api_url=API_URL,
        temperature=TEMPERATURE,
    )

    # æ ¹æ®è®°å¿†æ¨¡å¼åˆå§‹åŒ–å¯¹è¯å†å²
    if args.memory_mode == 'long':
        conversation_history = memory_store.load(session_id)
        if conversation_history:
            print(f"ğŸ—„ å·²åŠ è½½ä¼šè¯ '{session_id}' çš„å†å²æ¶ˆæ¯ï¼Œå…± {len(conversation_history)} æ¡ã€‚")
        else:
            print(f"ğŸ—„ ä¼šè¯ '{session_id}' æš‚æ— å†å²ï¼Œå°†ä»å¤´å¼€å§‹ã€‚")
    else:
        conversation_history = []
        print("AIå°åŠ©æ‰‹ï¼šä½ å¥½ï¼ä¸€ä¸ªæ–°çš„æ—…ç¨‹å¼€å§‹äº†ã€‚")

    file_context = None
    # æ£€æŸ¥ file_path æ˜¯å¦è¢«æä¾›ï¼Œå¹¶è¿›è¡Œç›¸åº”çš„å¤„ç†
    if args.file_path:
        # å¦‚æœ file_path æ˜¯ä¸€ä¸ªç›®å½•ï¼Œæç¤ºç”¨æˆ·ä½¿ç”¨æ‰¹é‡æ€»ç»“è„šæœ¬
        if os.path.isdir(args.file_path):
            print("ğŸ“ æ£€æµ‹åˆ°æ–‡ä»¶å¤¹è¾“å…¥ã€‚")
            print("æ­¤åŠŸèƒ½å·²ç§»è‡³æ–°è„šæœ¬ `note_process/batch_summarize.py`ã€‚")
            print("è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿è¡Œæ‰¹é‡æ€»ç»“åŠŸèƒ½:")
            print(f"   python note_process/batch_summarize.py \"{args.file_path}\"")
            sys.exit(0)
        # å¦‚æœ file_path æ˜¯ä¸€ä¸ªæ–‡ä»¶ï¼ŒåŠ è½½å…¶å†…å®¹
        elif os.path.isfile(args.file_path):
            try:
                with open(args.file_path, 'r', encoding='utf-8') as f:
                    file_context = f.read()
                print(f"ğŸ“ å·²åŠ è½½æ–‡ä»¶ '{os.path.basename(args.file_path)}'ã€‚ç°åœ¨æ‚¨å¯ä»¥åŸºäºè¯¥æ–‡ä»¶æé—®äº†ã€‚")
            except FileNotFoundError:
                print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {args.file_path}ã€‚è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
                sys.exit(1) # æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œç¨‹åºé€€å‡º
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
                sys.exit(1) # å…¶ä»–æ–‡ä»¶å¤„ç†é”™è¯¯ï¼Œç¨‹åºé€€å‡º
        # å¦‚æœ file_path æ—¢ä¸æ˜¯æ–‡ä»¶ä¹Ÿä¸æ˜¯ç›®å½•ï¼Œåˆ™æŠ¥é”™
        else:
            print(f"âŒ é”™è¯¯ï¼š'{args.file_path}' æ—¢ä¸æ˜¯æ–‡ä»¶ä¹Ÿä¸æ˜¯æ–‡ä»¶å¤¹ã€‚è¯·æä¾›æœ‰æ•ˆè·¯å¾„ã€‚")
            sys.exit(1)
    # ä½¿ç”¨ while True åˆ›å»ºä¸€ä¸ªæ— é™å¾ªç¯ï¼ŒæŒç»­æ¥æ”¶ç”¨æˆ·è¾“å…¥
    while True:
        # ä½¿ç”¨ input() æ¥è·å–ä½ åœ¨ç»ˆç«¯è¾“å…¥çš„é—®é¢˜
        user_input = input("ä½ ï¼š")

        # è®¾ç½®é€€å‡ºæ¡ä»¶ï¼šå½“ç”¨æˆ·è¾“å…¥ç‰¹å®šè¯æ±‡æ—¶ï¼Œä¿å­˜å†å²å¹¶é€€å‡ºå¾ªç¯
        # .lower() å°†è¾“å…¥è½¬ä¸ºå°å†™ï¼Œä½¿å¾—åˆ¤æ–­ä¸åŒºåˆ†å¤§å°å†™
        if user_input.lower() in ["quit", "exit","bye","goodbye","q","e"]:
            # ä»…åœ¨é•¿æœŸè®°å¿†æ¨¡å¼ä¸‹ä¿å­˜å†å²
            if args.memory_mode == 'long':
                memory_store.save(session_id, conversation_history)
            print("AIå°åŠ©æ‰‹ï¼šæœŸå¾…ä¸‹æ¬¡ä¸ä½ ç›¸è§ï¼")
            break

        # --- æ ¸å¿ƒä¿®æ”¹ï¼šåŠ¨æ€æ„å»ºç”¨æˆ·è¾“å…¥ ---
        # å¦‚æœå­˜åœ¨æ–‡ä»¶ä¸Šä¸‹æ–‡ï¼Œåˆ™å°†å…¶ä¸ç”¨æˆ·å½“å‰é—®é¢˜ç»„åˆ
        if file_context:
            # æ„å»ºä¸€ä¸ªåŒ…å«æ–‡ä»¶ä¸Šä¸‹æ–‡å’Œç”¨æˆ·é—®é¢˜çš„å¤åˆæç¤º
            final_input = f"""è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹æ¥å›ç­”æˆ‘çš„é—®é¢˜ã€‚
---
æ–‡æ¡£å†…å®¹:
{file_context}
---
æˆ‘çš„é—®é¢˜æ˜¯ï¼š{user_input}
"""
        else:
            # å¦‚æœæ²¡æœ‰æ–‡ä»¶ä¸Šä¸‹æ–‡ï¼Œåˆ™ç›´æ¥ä½¿ç”¨ç”¨æˆ·è¾“å…¥
            final_input = user_input

        # æ— è®ºä½•ç§æ¨¡å¼ï¼Œéƒ½å°†ç”¨æˆ·çš„è¾“å…¥å­˜å…¥å®Œæ•´çš„å†å²è®°å½•ï¼Œä»¥å¤‡å°†æ¥ä¿å­˜
        conversation_history.append({"role": "user", "content": final_input})

        # --- 3. æ ¹æ®è®°å¿†æ¨¡å¼å†³å®šå‘é€ç»™ AI çš„å†…å®¹ ---
        if args.memory_mode == 'no':
            # æ— è®°å¿†æ¨¡å¼ï¼šåªå‘é€åŒ…å«å½“å‰è¿™ä¸€æ¬¡è¾“å…¥çš„æ–°åˆ—è¡¨
            history_to_send = [conversation_history[-1]]
        else: # 'short' å’Œ 'long' æ¨¡å¼éƒ½ä½¿ç”¨çŸ­æœŸè®°å¿†
            # çŸ­æœŸ/é•¿æœŸè®°å¿†æ¨¡å¼ï¼šå‘é€åŒ…å«æ‰€æœ‰å†å²è®°å½•çš„å®Œæ•´åˆ—è¡¨
            history_to_send = conversation_history

        # è°ƒç”¨ç”Ÿæˆå™¨å‡½æ•°ï¼Œå¹¶è¿­ä»£æ‰“å°ç»“æœ
        print(f"AIåŠ©æ‰‹ï¼š", end="")
        full_response = ""
        has_error = False
        # è°ƒç”¨ AI æœåŠ¡å®ä¾‹çš„æ–¹æ³•
        for chunk in ai_service.stream_chat_completion(history_to_send):
            # æ£€æŸ¥è¿”å›çš„ç‰‡æ®µä¸­æ˜¯å¦åŒ…å«é”™è¯¯ä¿¡æ¯
            if "ç½‘ç»œé”™è¯¯" in chunk or "æœªçŸ¥é”™è¯¯" in chunk:
                has_error = True
            full_response += chunk
            # flush=True å¼ºåˆ¶åˆ·æ–°è¾“å‡ºç¼“å†²åŒºï¼Œç¡®ä¿å†…å®¹èƒ½è¢«ç«‹å³æ˜¾ç¤º
            print(chunk, end="", flush=True)
        print() # ç»“æŸæ—¶æ¢è¡Œ

        # æ— è®ºä½•ç§æ¨¡å¼ï¼Œéƒ½å°†AIçš„å›ç­”ä¹Ÿå­˜å…¥å®Œæ•´çš„å†å²è®°å½•
        # (ç¡®ä¿ä¸ä¼šæŠŠé”™è¯¯ä¿¡æ¯ä¹Ÿè®°ä¸‹æ¥), ä»¥å¤‡å°†æ¥ä¿å­˜
        if not has_error:
            conversation_history.append({"role": "assistant", "content": full_response})
        
        print("\n" + "-"*30) #æ‰“å°åˆ†éš”çº¿ï¼Œå¹¶åœ¨å‰é¢åŠ ä¸€ä¸ªæ¢è¡Œä»¥æ”¹å–„é—´è·

# --- 5. å›¾å½¢ç”¨æˆ·ç•Œé¢ (GUI) å¯åŠ¨é€»è¾‘ ---
def start_gui():
    """å¯åŠ¨ Gradio å›¾å½¢ç”¨æˆ·ç•Œé¢ã€‚"""
    print("ğŸš€ æ­£åœ¨å¯åŠ¨ Gradio å›¾å½¢ç•Œé¢...")

    # --- æ–°å¢ï¼šåˆå§‹åŒ– AI æœåŠ¡ ---
    ai_service = AIAssistantService(
        api_key=API_KEY,
        model_name=MODEL_NAME,
        api_url=API_URL,
        temperature=TEMPERATURE,
    )

    # --- ä¸º Gradio UI ç¼–å†™çš„æ¥å£å‡½æ•° ---
    def chat_response(user_input, chatbot_history, conversation_state):
        """å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œå¹¶æµå¼è¿”å›AIå“åº”"""
        # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°å¯¹è¯å†å²çŠ¶æ€
        conversation_state.append({"role": "user", "content": user_input})
        # æ›´æ–°Chatbot UIä»¥ç«‹å³æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
        chatbot_history.append([user_input, ""])
        # yield å…³é”®å­—ä½¿è¿™ä¸ªå‡½æ•°æˆä¸ºä¸€ä¸ªç”Ÿæˆå™¨ï¼Œå¯ä»¥é€æ­¥è¿”å›UIæ›´æ–°
        yield chatbot_history, conversation_state

        # æµå¼è·å–AIå›å¤
        full_response = ""
        has_error = False
        # è°ƒç”¨ AI æœåŠ¡å®ä¾‹çš„æ–¹æ³•
        for chunk in ai_service.stream_chat_completion(conversation_state):
            if "ç½‘ç»œé”™è¯¯" in chunk or "æœªçŸ¥é”™è¯¯" in chunk:
                has_error = True
            full_response += chunk
            chatbot_history[-1][1] = full_response # æ›´æ–°èŠå¤©æœºå™¨äººç•Œé¢ä¸­æœ€åä¸€æ¡æ¶ˆæ¯çš„AIå›å¤éƒ¨åˆ†
            yield chatbot_history, conversation_state

        # å¦‚æœæ²¡æœ‰é”™è¯¯ï¼Œå°†å®Œæ•´çš„AIå›å¤æ·»åŠ åˆ°å¯¹è¯å†å²çŠ¶æ€
        # æ³¨æ„ï¼šGradioç‰ˆæœ¬ä¸­ï¼Œå†å²è®°å½•æ˜¯ä¸´æ—¶çš„ï¼Œåªåœ¨å½“å‰ä¼šè¯ä¸­æœ‰æ•ˆï¼Œå…³é—­å³ä¸¢å¤±
        if not has_error:
            conversation_state.append({"role": "assistant", "content": full_response})

    # --- æ„å»º Gradio ç•Œé¢ ---
    with gr.Blocks(title="AI åŠ©æ‰‹") as app:
        # gr.State ç”¨äºåœ¨åç«¯å­˜å‚¨ä¼šè¯æœŸé—´çš„å®Œæ•´å¯¹è¯å†å²ï¼ˆåŒ…å«system roleç­‰ï¼‰
        # å®ƒåœ¨å‰ç«¯æ˜¯ä¸å¯è§çš„
        conversation_state = gr.State(value=[])

        gr.Markdown("# ğŸ¤– AI åŠ©æ‰‹")
        gr.Markdown("ä¸€ä¸ªç”±é˜¿é‡Œé€šä¹‰åƒé—®é©±åŠ¨çš„æ™ºèƒ½åŠ©æ‰‹ã€‚")

        # ä¸»è¦èŠå¤©ç•Œé¢
        chatbot = gr.Chatbot(label="é€šä¹‰åƒé—®", height=500)
        
        with gr.Row():
            txt_input = gr.Textbox(show_label=False, lines=3, placeholder="è¯¢é—®ä»»ä½•é—®é¢˜", scale=8)
            btn_submit = gr.Button("å‘é€", variant="primary", scale=1)

        # --- ç»‘å®šäº‹ä»¶ ---
        # å°†æäº¤åŠ¨ä½œï¼ˆæŒ‰å›è½¦æˆ–ç‚¹å‡»æŒ‰é’®ï¼‰ç»‘å®šåˆ° chat_response å‡½æ•°
        txt_input.submit(chat_response, [txt_input, chatbot, conversation_state], [chatbot, conversation_state]).then(lambda: "", [], [txt_input])
        btn_submit.click(chat_response, [txt_input, chatbot, conversation_state], [chatbot, conversation_state]).then(lambda: "", [], [txt_input])

    # å¯åŠ¨Gradioåº”ç”¨
    app.launch()

# --- 6. ä¸»ç¨‹åºæ‰§è¡Œå…¥å£ ---
# ä¸‹é¢çš„ä»£ç åªæœ‰åœ¨ç›´æ¥è¿è¡Œ `python ai_assistant.py` æ—¶æ‰ä¼šæ‰§è¡Œ
if __name__ == "__main__":
    # ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦è¦å¯åŠ¨ GUI æ¨¡å¼
    if '--gui' in sys.argv:
        start_gui()
    else:
        # å¦åˆ™ï¼Œå¯åŠ¨é»˜è®¤çš„å‘½ä»¤è¡Œæ¨¡å¼
        # start_cli å‡½æ•°å†…éƒ¨ä¼šä½¿ç”¨ argparse å¤„ç†æ‰€æœ‰ç›¸å…³çš„å‘½ä»¤è¡Œå‚æ•°
        start_cli()
